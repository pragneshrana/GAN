{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Tutorial\n",
    "Open CV Tutorial for processing video and images \\\n",
    "Code contains some command of openCV and implementation of readymade blocks from some blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "print( cv2.__version__ )\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing video from webcam and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[ 6  2  5]\n",
      "  [ 7  3  6]\n",
      "  [ 7  3  6]\n",
      "  ...\n",
      "  [ 9  6  9]\n",
      "  [ 8  9  7]\n",
      "  [ 8  9  7]]\n",
      "\n",
      " [[ 6  2  5]\n",
      "  [ 7  3  6]\n",
      "  [ 7  3  6]\n",
      "  ...\n",
      "  [10  7 10]\n",
      "  [ 6  9  7]\n",
      "  [ 6  9  7]]\n",
      "\n",
      " [[ 3  5  5]\n",
      "  [ 3  5  5]\n",
      "  [ 6  2  5]\n",
      "  ...\n",
      "  [ 6  9  8]\n",
      "  [ 6  9  7]\n",
      "  [ 6  9  7]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8  5  7]\n",
      "  [ 9  6  9]\n",
      "  [ 5  7  7]\n",
      "  ...\n",
      "  [ 8  5  7]\n",
      "  [ 8  5  7]\n",
      "  [ 8  5  7]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 5  7  7]\n",
      "  ...\n",
      "  [ 8  5  7]\n",
      "  [ 8  5  7]\n",
      "  [ 8  5  7]]\n",
      "\n",
      " [[ 7  8  5]\n",
      "  [ 7  8  5]\n",
      "  [ 5  7  7]\n",
      "  ...\n",
      "  [ 8  5  7]\n",
      "  [ 7  3  6]\n",
      "  [ 7  3  6]]]\n",
      "ret True\n",
      "[[[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 7  8  5]\n",
      "  ...\n",
      "  [ 9 24 19]\n",
      "  [11 25 18]\n",
      "  [11 25 18]]\n",
      "\n",
      " [[ 8  5  7]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [11 26 23]\n",
      "  [10 25 21]\n",
      "  [10 25 21]]\n",
      "\n",
      " [[ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [11 28 26]\n",
      "  [ 8 28 24]\n",
      "  [ 7 26 23]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2 22 19]\n",
      "  [ 2 22 19]\n",
      "  [ 7 19 17]\n",
      "  ...\n",
      "  [15 12 14]\n",
      "  [13 14 11]\n",
      "  [12 12 10]]\n",
      "\n",
      " [[ 5 20 17]\n",
      "  [ 5 20 17]\n",
      "  [ 9 19 17]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]\n",
      "\n",
      " [[ 7 19 17]\n",
      "  [ 7 19 17]\n",
      "  [10 17 16]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]]\n",
      "ret True\n",
      "[[[ 9  6  9]\n",
      "  [10  7 10]\n",
      "  [ 6  9  8]\n",
      "  ...\n",
      "  [16 23 22]\n",
      "  [14 24 22]\n",
      "  [14 24 22]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [18 26 24]\n",
      "  [16 26 24]\n",
      "  [16 26 24]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [18 27 26]\n",
      "  [18 27 26]\n",
      "  [19 28 27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9 19 17]\n",
      "  [ 9 19 17]\n",
      "  [11 19 17]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]\n",
      "\n",
      " [[10 17 16]\n",
      "  [10 17 16]\n",
      "  [13 18 17]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]\n",
      "\n",
      " [[10 17 16]\n",
      "  [10 17 16]\n",
      "  [11 19 17]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]]\n",
      "ret True\n",
      "[[[ 9  6  9]\n",
      "  [10  7 10]\n",
      "  [10  7 10]\n",
      "  ...\n",
      "  [11 23 21]\n",
      "  [15 22 21]\n",
      "  [15 22 21]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 7  8  5]\n",
      "  ...\n",
      "  [15 21 23]\n",
      "  [17 20 24]\n",
      "  [18 21 25]]\n",
      "\n",
      " [[ 7  8  5]\n",
      "  [ 7  8  5]\n",
      "  [ 7  8  5]\n",
      "  ...\n",
      "  [14 23 24]\n",
      "  [14 21 27]\n",
      "  [14 21 27]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5 20 17]\n",
      "  [ 7 21 19]\n",
      "  [ 9 21 19]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [14 10 13]]\n",
      "\n",
      " [[ 9 21 19]\n",
      "  [ 9 21 19]\n",
      "  [ 9 21 19]\n",
      "  ...\n",
      "  [14 10 13]\n",
      "  [14 10 13]\n",
      "  [15 12 14]]\n",
      "\n",
      " [[ 9 21 19]\n",
      "  [ 7 19 17]\n",
      "  [ 7 19 17]\n",
      "  ...\n",
      "  [14  9 16]\n",
      "  [14  9 16]\n",
      "  [14  9 16]]]\n",
      "ret True\n",
      "[[[ 9 16 15]\n",
      "  [10 17 16]\n",
      "  [14 17 16]\n",
      "  ...\n",
      "  [44 57 57]\n",
      "  [44 60 53]\n",
      "  [44 60 53]]\n",
      "\n",
      " [[ 8 15 14]\n",
      "  [ 9 16 15]\n",
      "  [11 16 15]\n",
      "  ...\n",
      "  [44 57 57]\n",
      "  [45 61 54]\n",
      "  [45 61 54]]\n",
      "\n",
      " [[ 8 15 14]\n",
      "  [ 8 15 14]\n",
      "  [11 16 15]\n",
      "  ...\n",
      "  [42 58 57]\n",
      "  [45 59 57]\n",
      "  [46 61 58]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[34 53 50]\n",
      "  [34 53 50]\n",
      "  [38 52 50]\n",
      "  ...\n",
      "  [45 39 42]\n",
      "  [44 38 41]\n",
      "  [42 37 40]]\n",
      "\n",
      " [[34 53 50]\n",
      "  [34 53 50]\n",
      "  [40 52 50]\n",
      "  ...\n",
      "  [44 41 43]\n",
      "  [41 42 39]\n",
      "  [38 39 37]]\n",
      "\n",
      " [[36 53 50]\n",
      "  [36 53 50]\n",
      "  [40 52 50]\n",
      "  ...\n",
      "  [42 38 41]\n",
      "  [36 39 38]\n",
      "  [36 39 38]]]\n",
      "ret True\n",
      "[[[16 13 16]\n",
      "  [17 14 17]\n",
      "  [15 16 14]\n",
      "  ...\n",
      "  [42 57 59]\n",
      "  [42 59 56]\n",
      "  [42 59 56]]\n",
      "\n",
      " [[14 15 12]\n",
      "  [15 16 14]\n",
      "  [14 15 12]\n",
      "  ...\n",
      "  [43 58 60]\n",
      "  [43 59 59]\n",
      "  [42 58 57]]\n",
      "\n",
      " [[14 15 12]\n",
      "  [15 16 14]\n",
      "  [15 16 14]\n",
      "  ...\n",
      "  [45 57 62]\n",
      "  [45 57 62]\n",
      "  [45 57 62]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[26 52 48]\n",
      "  [28 54 50]\n",
      "  [34 53 50]\n",
      "  ...\n",
      "  [44 41 43]\n",
      "  [41 44 41]\n",
      "  [41 44 41]]\n",
      "\n",
      " [[27 53 49]\n",
      "  [27 53 49]\n",
      "  [36 53 50]\n",
      "  ...\n",
      "  [44 41 43]\n",
      "  [37 42 41]\n",
      "  [37 42 41]]\n",
      "\n",
      " [[30 54 50]\n",
      "  [30 54 50]\n",
      "  [36 53 50]\n",
      "  ...\n",
      "  [42 38 43]\n",
      "  [35 35 42]\n",
      "  [35 35 42]]]\n",
      "ret True\n",
      "[[[ 41  44  50]\n",
      "  [ 44  46  53]\n",
      "  [ 43  49  50]\n",
      "  ...\n",
      "  [ 85 107 104]\n",
      "  [ 82 111 106]\n",
      "  [ 85 114 109]]\n",
      "\n",
      " [[ 35  45  43]\n",
      "  [ 36  46  44]\n",
      "  [ 41  48  47]\n",
      "  ...\n",
      "  [ 86 110 106]\n",
      "  [ 86 110 106]\n",
      "  [ 86 110 106]]\n",
      "\n",
      " [[ 33  47  40]\n",
      "  [ 32  45  39]\n",
      "  [ 41  48  42]\n",
      "  ...\n",
      "  [ 86 109 108]\n",
      "  [ 87 107 106]\n",
      "  [ 84 105 104]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 69 100  97]\n",
      "  [ 70 101  98]\n",
      "  [ 73 100  95]\n",
      "  ...\n",
      "  [ 96  81  85]\n",
      "  [102  79  85]\n",
      "  [101  78  84]]\n",
      "\n",
      " [[ 68 100 100]\n",
      "  [ 68 100 100]\n",
      "  [ 72 101  97]\n",
      "  ...\n",
      "  [ 89  81  84]\n",
      "  [ 93  80  84]\n",
      "  [ 90  78  82]]\n",
      "\n",
      " [[ 66 102  98]\n",
      "  [ 66 102  98]\n",
      "  [ 72 101  97]\n",
      "  ...\n",
      "  [ 88  82  85]\n",
      "  [ 88  79  83]\n",
      "  [ 84  76  80]]]\n",
      "ret True\n",
      "[[[ 35  45  43]\n",
      "  [ 40  49  48]\n",
      "  [ 38  52  50]\n",
      "  ...\n",
      "  [ 79 112 109]\n",
      "  [ 83 112 107]\n",
      "  [ 84 113 108]]\n",
      "\n",
      " [[ 29  40  43]\n",
      "  [ 35  46  49]\n",
      "  [ 36  50  48]\n",
      "  ...\n",
      "  [ 81 111 109]\n",
      "  [ 85 111 107]\n",
      "  [ 84 110 106]]\n",
      "\n",
      " [[ 28  39  42]\n",
      "  [ 33  43  46]\n",
      "  [ 34  49  47]\n",
      "  ...\n",
      "  [ 84 113 108]\n",
      "  [ 85 111 107]\n",
      "  [ 84 110 106]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 76 101  95]\n",
      "  [ 76 101  95]\n",
      "  [ 74 101  97]\n",
      "  ...\n",
      "  [ 96  74  80]\n",
      "  [ 94  76  76]\n",
      "  [ 96  78  79]]\n",
      "\n",
      " [[ 78 101  95]\n",
      "  [ 78 101  95]\n",
      "  [ 76 101  97]\n",
      "  ...\n",
      "  [ 91  73  78]\n",
      "  [ 92  74  80]\n",
      "  [ 93  76  81]]\n",
      "\n",
      " [[ 78 102  93]\n",
      "  [ 78 102  93]\n",
      "  [ 76 101  95]\n",
      "  ...\n",
      "  [ 94  70  80]\n",
      "  [ 91  72  82]\n",
      "  [ 92  73  83]]]\n",
      "ret True\n",
      "[[[ 54  55  57]\n",
      "  [ 55  57  59]\n",
      "  [ 63  59  64]\n",
      "  ...\n",
      "  [110 126 130]\n",
      "  [113 124 127]\n",
      "  [112 123 125]]\n",
      "\n",
      " [[ 54  48  60]\n",
      "  [ 58  51  64]\n",
      "  [ 61  57  64]\n",
      "  ...\n",
      "  [115 127 132]\n",
      "  [111 123 128]\n",
      "  [110 122 127]]\n",
      "\n",
      " [[ 50  50  57]\n",
      "  [ 53  53  59]\n",
      "  [ 59  54  62]\n",
      "  ...\n",
      "  [117 127 130]\n",
      "  [112 125 128]\n",
      "  [111 124 127]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87 121 115]\n",
      "  [ 87 121 115]\n",
      "  [ 85 121 115]\n",
      "  ...\n",
      "  [108  78  85]\n",
      "  [114  81  89]\n",
      "  [115  83  90]]\n",
      "\n",
      " [[ 87 121 115]\n",
      "  [ 87 121 115]\n",
      "  [ 88 119 114]\n",
      "  ...\n",
      "  [109  76  86]\n",
      "  [113  83  90]\n",
      "  [115  85  92]]\n",
      "\n",
      " [[ 83 121 115]\n",
      "  [ 83 121 115]\n",
      "  [ 88 119 114]\n",
      "  ...\n",
      "  [107  77  91]\n",
      "  [112  83  94]\n",
      "  [115  86  98]]]\n",
      "ret True\n",
      "[[[ 50  61  57]\n",
      "  [ 50  61  57]\n",
      "  [ 50  61  57]\n",
      "  ...\n",
      "  [105 128 122]\n",
      "  [113 128 119]\n",
      "  [112 127 117]]\n",
      "\n",
      " [[ 46  58  56]\n",
      "  [ 46  58  56]\n",
      "  [ 49  59  55]\n",
      "  ...\n",
      "  [110 128 123]\n",
      "  [115 132 120]\n",
      "  [112 130 118]]\n",
      "\n",
      " [[ 45  55  54]\n",
      "  [ 47  56  55]\n",
      "  [ 46  58  56]\n",
      "  ...\n",
      "  [113 130 125]\n",
      "  [118 130 121]\n",
      "  [118 130 121]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 90 120 112]\n",
      "  [ 90 120 112]\n",
      "  [ 92 118 114]\n",
      "  ...\n",
      "  [ 92  74  80]\n",
      "  [ 99  73  75]\n",
      "  [ 98  72  74]]\n",
      "\n",
      " [[ 90 120 112]\n",
      "  [ 90 120 112]\n",
      "  [ 93 117 113]\n",
      "  ...\n",
      "  [ 91  65  74]\n",
      "  [ 98  68  75]\n",
      "  [102  72  80]]\n",
      "\n",
      " [[ 90 120 112]\n",
      "  [ 89 118 111]\n",
      "  [ 96 115 112]\n",
      "  ...\n",
      "  [ 91  63  79]\n",
      "  [100  69  80]\n",
      "  [106  74  86]]]\n",
      "ret True\n",
      "[[[ 60  62  62]\n",
      "  [ 63  66  65]\n",
      "  [ 64  72  68]\n",
      "  ...\n",
      "  [123 133 132]\n",
      "  [119 134 132]\n",
      "  [117 132 129]]\n",
      "\n",
      " [[ 56  59  57]\n",
      "  [ 62  65  62]\n",
      "  [ 64  68  65]\n",
      "  ...\n",
      "  [123 135 133]\n",
      "  [121 135 133]\n",
      "  [121 135 133]]\n",
      "\n",
      " [[ 58  60  55]\n",
      "  [ 61  62  57]\n",
      "  [ 63  65  58]\n",
      "  ...\n",
      "  [123 137 135]\n",
      "  [123 137 135]\n",
      "  [122 136 134]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 99 125 121]\n",
      "  [100 127 122]\n",
      "  [105 127 123]\n",
      "  ...\n",
      "  [118  92  94]\n",
      "  [116  94  91]\n",
      "  [117  95  92]]\n",
      "\n",
      " [[ 97 126 121]\n",
      "  [ 98 127 122]\n",
      "  [101 125 121]\n",
      "  ...\n",
      "  [115  90  92]\n",
      "  [116  94  91]\n",
      "  [116  94  91]]\n",
      "\n",
      " [[ 97 126 121]\n",
      "  [ 98 127 122]\n",
      "  [ 99 125 121]\n",
      "  ...\n",
      "  [115  88  95]\n",
      "  [116  92  94]\n",
      "  [117  94  95]]]\n",
      "ret True\n",
      "[[[ 59  66  65]\n",
      "  [ 61  69  68]\n",
      "  [ 61  68  73]\n",
      "  ...\n",
      "  [125 134 130]\n",
      "  [130 134 127]\n",
      "  [128 133 126]]\n",
      "\n",
      " [[ 59  61  61]\n",
      "  [ 61  63  63]\n",
      "  [ 62  63  67]\n",
      "  ...\n",
      "  [129 134 131]\n",
      "  [131 134 131]\n",
      "  [131 134 131]]\n",
      "\n",
      " [[ 56  57  53]\n",
      "  [ 57  59  54]\n",
      "  [ 63  59  62]\n",
      "  ...\n",
      "  [130 134 128]\n",
      "  [133 134 131]\n",
      "  [135 136 133]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[101 129 120]\n",
      "  [101 129 120]\n",
      "  [103 128 122]\n",
      "  ...\n",
      "  [113  97  97]\n",
      "  [110  99  99]\n",
      "  [111 100 100]]\n",
      "\n",
      " [[ 99 130 120]\n",
      "  [ 99 130 120]\n",
      "  [105 128 122]\n",
      "  ...\n",
      "  [111  97  97]\n",
      "  [112  97 102]\n",
      "  [112  97 102]]\n",
      "\n",
      " [[101 129 120]\n",
      "  [101 129 120]\n",
      "  [109 127 122]\n",
      "  ...\n",
      "  [113  95 101]\n",
      "  [111  96 101]\n",
      "  [111  96 101]]]\n",
      "ret True\n",
      "[[[ 65  66  64]\n",
      "  [ 69  69  67]\n",
      "  [ 74  74  67]\n",
      "  ...\n",
      "  [119 144 140]\n",
      "  [121 140 137]\n",
      "  [120 139 136]]\n",
      "\n",
      " [[ 60  62  62]\n",
      "  [ 63  66  65]\n",
      "  [ 66  67  65]\n",
      "  ...\n",
      "  [117 144 140]\n",
      "  [119 144 140]\n",
      "  [118 142 139]]\n",
      "\n",
      " [[ 56  59  58]\n",
      "  [ 60  62  62]\n",
      "  [ 66  63  66]\n",
      "  ...\n",
      "  [118 142 139]\n",
      "  [119 144 140]\n",
      "  [121 145 141]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[110 128 123]\n",
      "  [113 130 125]\n",
      "  [113 132 122]\n",
      "  ...\n",
      "  [126 113 112]\n",
      "  [125 111 111]\n",
      "  [124 110 110]]\n",
      "\n",
      " [[106 132 121]\n",
      "  [104 131 120]\n",
      "  [113 131 124]\n",
      "  ...\n",
      "  [129 109 115]\n",
      "  [126 110 110]\n",
      "  [125 109 109]]\n",
      "\n",
      " [[106 130 124]\n",
      "  [106 130 124]\n",
      "  [112 129 124]\n",
      "  ...\n",
      "  [127 109 115]\n",
      "  [125 111 111]\n",
      "  [125 111 111]]]\n",
      "ret True\n",
      "[[[ 66  62  60]\n",
      "  [ 67  63  61]\n",
      "  [ 70  66  65]\n",
      "  ...\n",
      "  [124 142 137]\n",
      "  [130 141 137]\n",
      "  [130 141 137]]\n",
      "\n",
      " [[ 63  64  61]\n",
      "  [ 63  64  61]\n",
      "  [ 70  62  66]\n",
      "  ...\n",
      "  [128 143 138]\n",
      "  [135 143 139]\n",
      "  [134 142 138]]\n",
      "\n",
      " [[ 63  64  60]\n",
      "  [ 65  67  62]\n",
      "  [ 69  65  64]\n",
      "  ...\n",
      "  [130 145 140]\n",
      "  [137 142 141]\n",
      "  [136 140 140]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108 136 127]\n",
      "  [108 136 127]\n",
      "  [116 134 129]\n",
      "  ...\n",
      "  [154 146 142]\n",
      "  [150 141 140]\n",
      "  [148 139 138]]\n",
      "\n",
      " [[105 135 128]\n",
      "  [105 135 128]\n",
      "  [115 132 129]\n",
      "  ...\n",
      "  [149 144 140]\n",
      "  [149 140 139]\n",
      "  [148 139 138]]\n",
      "\n",
      " [[102 134 126]\n",
      "  [103 135 128]\n",
      "  [115 132 129]\n",
      "  ...\n",
      "  [148 142 140]\n",
      "  [151 138 142]\n",
      "  [150 137 141]]]\n",
      "ret True\n",
      "[[[ 72  80  65]\n",
      "  [ 75  82  67]\n",
      "  [ 75  80  70]\n",
      "  ...\n",
      "  [138 144 140]\n",
      "  [139 143 138]\n",
      "  [139 143 138]]\n",
      "\n",
      " [[ 67  79  64]\n",
      "  [ 68  81  65]\n",
      "  [ 70  79  68]\n",
      "  ...\n",
      "  [136 144 140]\n",
      "  [139 142 139]\n",
      "  [139 142 139]]\n",
      "\n",
      " [[ 65  70  63]\n",
      "  [ 68  73  65]\n",
      "  [ 69  75  65]\n",
      "  ...\n",
      "  [136 143 142]\n",
      "  [139 142 139]\n",
      "  [138 141 138]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[106 139 131]\n",
      "  [105 137 130]\n",
      "  [105 137 130]\n",
      "  ...\n",
      "  [158 137 138]\n",
      "  [160 137 136]\n",
      "  [159 136 135]]\n",
      "\n",
      " [[108 139 130]\n",
      "  [107 138 128]\n",
      "  [109 137 130]\n",
      "  ...\n",
      "  [151 135 136]\n",
      "  [157 137 135]\n",
      "  [157 137 135]]\n",
      "\n",
      " [[108 136 127]\n",
      "  [108 136 127]\n",
      "  [110 135 129]\n",
      "  ...\n",
      "  [155 130 137]\n",
      "  [158 134 136]\n",
      "  [160 137 138]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[ 70  71  68]\n",
      "  [ 71  72  69]\n",
      "  [ 71  75  72]\n",
      "  ...\n",
      "  [127 144 139]\n",
      "  [132 146 137]\n",
      "  [131 145 136]]\n",
      "\n",
      " [[ 62  65  62]\n",
      "  [ 65  69  66]\n",
      "  [ 67  70  67]\n",
      "  ...\n",
      "  [131 146 143]\n",
      "  [131 144 139]\n",
      "  [131 144 139]]\n",
      "\n",
      " [[ 65  59  62]\n",
      "  [ 67  61  64]\n",
      "  [ 65  66  64]\n",
      "  ...\n",
      "  [133 145 143]\n",
      "  [134 144 140]\n",
      "  [133 143 139]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108 140 128]\n",
      "  [108 140 128]\n",
      "  [113 139 128]\n",
      "  ...\n",
      "  [160 142 143]\n",
      "  [164 149 140]\n",
      "  [165 150 141]]\n",
      "\n",
      " [[111 137 128]\n",
      "  [111 137 128]\n",
      "  [112 136 127]\n",
      "  ...\n",
      "  [160 143 141]\n",
      "  [164 149 140]\n",
      "  [165 150 141]]\n",
      "\n",
      " [[110 136 127]\n",
      "  [110 136 127]\n",
      "  [112 135 129]\n",
      "  ...\n",
      "  [156 144 141]\n",
      "  [160 150 140]\n",
      "  [163 153 143]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0\n",
    "frames = 20\n",
    "while(count < frames):\n",
    "    count += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    print('ret',ret)\n",
    "    print(frame)\n",
    "    # Our operations on the frame come here    \n",
    "    img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(img,0)     # flip up-down\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record and Save the Video from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create writer object\n",
    "fileName='out.avi'  # change the file name if needed\n",
    "imgSize=(640,480)\n",
    "frame_per_second=30.0\n",
    "writer = cv2.VideoWriter(fileName, cv2.VideoWriter_fourcc(*\"MJPG\"), frame_per_second,imgSize)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "start_time = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        writer.write(frame)                   # save the frame into video file\n",
    "        cv2.imshow('Video Capture',frame)     # show on the screen\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # press q to Quit, where? : In video window\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the video and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='out.avi'  # change the file name if needed\n",
    "\n",
    "cap = cv2.VideoCapture(fileName)          # load the video\n",
    "while(cap.isOpened()):                    # play the video by reading frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        # optional: do some image processing here \n",
    "        cv2.imshow('frame',frame)              # show the video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the recording window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factorx=0.5\n",
    "scaling_factory=0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # set frame size (e.g. 640x480; 320x240; 960x720), larger is slower    \n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_WIDTH,320)\n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_HEIGHT,240)\n",
    "    frame=cv2.resize(frame,None,fx=scaling_factorx,fy=scaling_factory,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    img = frame\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Smaller Window',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Colour Transformation\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR color to RGB\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # RGB color to BGR\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)  # RGB color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)   # BGR color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HSV)   # RGB color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HLS)   # RGB color to HLS\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HLS)   # BGR color to HLS\n",
    "    img = cv2.cvtColor(frame,cv2.COLOR_BGR2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2Lab)   # BGR color to CIE L\\*a\\*b\\*\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2Luv)   # RGB color to CIE L\\*u\\*v\\*\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Gray',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Enhancement\n",
    "\n",
    "Change the contrast of image using Histogram equalization. \\\n",
    "command : equalizeHist() -- only for gray scale image \\\n",
    "\n",
    "Ref : https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = frame\n",
    "    img = equalizeHistColor(frame)\n",
    "    \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Histogram Equalization',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16ca950ab9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# start video capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Capture frame-by-frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def WarpImage(frame):\n",
    "    ax,bx=10.0,100\n",
    "    ay,by=20.0,120\n",
    "    img=np.zeros(frame.shape,dtype=frame.dtype)\n",
    "    rows,cols=img.shape[:2]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x=int(ax*math.sin(2*math.pi*i/bx))\n",
    "            offset_y=int(ay*math.cos(2*math.pi*j/by))\n",
    "            if i+offset_y<rows and j+offset_x<cols:\n",
    "                img[i,j]=frame[(i+offset_y)%rows,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img[i,j]=0\n",
    "    return img\n",
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() \n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    if ret==1:\n",
    "        #img = WarpImage(frame)\n",
    "        img = equalizeHistColor(WarpImage(frame))\n",
    "    else:\n",
    "        img = equalizeHistColor(frame)\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Warped',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=5\n",
    "parameter2=20\n",
    "intApertureSize=10\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    ## Smoothening Filters   \n",
    "    frame = cv2.GaussianBlur(frame, (kernelSize,kernelSize),0,0) # Gaussian Blur smoothing filter\n",
    "#     frame = cv2.medianBlur(frame, kernelSize) # Median Blur smoothing filter\n",
    "#     frame = cv2.blur(frame,(kernelSize,kernelSize)) # Average Blur smoothing filter\n",
    "#     frame = cv2.bilateralFilter(frame,9,75,75) # Bilateral Filter for smoothing filter\n",
    "    \n",
    "    ## Edge Detection Algorithm\n",
    "    frame = cv2.Canny(frame,parameter1,parameter2,intApertureSize) # Canny edge detection\n",
    "    frame = cv2.Laplacian(frame,cv2.CV_64F) # Laplacian edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=kernelSize) # X-direction Sobel edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=kernelSize) # Y-direction Sobel edge detection\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Canny',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Impose\n",
    "\n",
    "- edge detection as mask\n",
    "- superimpose it with the original image\n",
    "- Processing : reverse the edge detection result using bitwise Not to inverse it. Then, use bitwise and to superimpose with the blur image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=10\n",
    "parameter2=40\n",
    "intApertureSize=1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame1 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    frame = cv2.GaussianBlur(frame1, (kernelSize,kernelSize), 0, 0) \n",
    "    edge = cv2.Canny(frame,parameter1,parameter2,intApertureSize)  # Canny edge detection\n",
    "    mask_edge = cv2.bitwise_not(edge)\n",
    "    frame = cv2.bitwise_and(frame1,frame1,mask = mask_edge)   \n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Super Impose',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countour\n",
    "\n",
    "Functions:\n",
    "    - img, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,chainRuleApproximation)\n",
    "    - img=cv2.drawContours(img, contours, index, colorTuple, thickness)\n",
    "\n",
    "Arguments:\n",
    "    - img = image\n",
    "    - index=-1 means show all contours, 0-len(contours) means to show each contour\n",
    "    - chainRuleApproximation is either:\n",
    "        - cv2.CHAIN_APPROX_SIMPLE: to give only 4 points in a rectangle\n",
    "        - cv2.CHAIN_APPROX_NONE: to give all points\n",
    "    - colorTuple is any BGR color. For instance:\n",
    "        - (255,0,0) for Blue\n",
    "        - (0,255,0) for Green\n",
    "        - (0,0,255) for Red\n",
    "    - thickness is integer 1-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(gray,10,20,cv2.THRESH_BINARY_INV)\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)   \n",
    "    if len(contours) != 0:\n",
    "            c = max(contours, key = cv2.contourArea) # find the largest contour\n",
    "            x,y,w,h = cv2.boundingRect(c)          # get bounding box of largest contour\n",
    "            #img2=cv2.drawContours(frame, c, -1, color, thickness) # draw largest contour\n",
    "            img2 = cv2.drawContours(frame, contours, -1, color, thickness) # draw all contours\n",
    "            img3 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Contour',img3)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "-Generate mask using thresold. A mask is a binary image.\n",
    "\n",
    "Adaptive threshold has the following parameters:\n",
    "\n",
    "   - src – Source 8-bit single-channel image.\n",
    "   - dst – Destination image of the same size and the same type as src .\n",
    "   - maxValue – Non-zero value assigned to the pixels for which the condition is satisfied. Put 255.\n",
    "   - adaptiveMethod – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C .\n",
    "   - thresholdType – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV .\n",
    "   - blockSize – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "   - C – Constant subtracted from the mean or weighted mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "threshold1=100\n",
    "threshold2=200\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # equalize the histogram of color image\n",
    "    frame1 = equalizeHistColor(frame) \n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "     \n",
    "    ## Thresolding Method\n",
    "    ret, mask = cv2.threshold(blur, threshold1, threshold2, cv2.THRESH_BINARY)\n",
    "    ret, mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #ret, mask = cv2.threshold(blur,threshold1, threshold2,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    #mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((3, 3), np.uint8)  \n",
    "    mask=cv2.erode(mask,kernel,iterations=7) # morphology erosion   \n",
    "    mask=cv2.dilate(mask,kernel,iterations=5) # morphology dilation\n",
    "    \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    img = cv2.bitwise_and(frame1,frame1,mask = mask_inv)\n",
    "    img = cv2.addWeighted(frame1,0.1,img,0.9,0)\n",
    "    \n",
    "    #img=mask\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Thresholding-Otsu',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow\n",
    "- shows aura kinda.\n",
    "- motion of image objects between two consecutive frames caused by the movemement of object or camera.\n",
    "Ref : https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_lucas_kanade.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    prvs = next\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Optical Flow Aura',bgr)\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Detection by Image Difference\n",
    "\n",
    "- images are captured with a time delay of 1/25 seconds\n",
    "- After image difference, get the contour out of it \n",
    "- put the bounding box out of the contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture two frames\n",
    "    ret, frame1 = cap.read()  # first image\n",
    "    time.sleep(1/25)          # slight delay\n",
    "    ret, frame2 = cap.read()  # second image \n",
    "    img1 = cv2.absdiff(frame1,frame2)  # image difference\n",
    "    \n",
    "    # get theshold image\n",
    "    gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(blur,200,255,cv2.THRESH_OTSU)\n",
    "    \n",
    "    # combine frame and the image difference\n",
    "    img2 = cv2.addWeighted(frame1,0.9,img1,0.1,0)\n",
    "    \n",
    "    # get contours and set bounding box from contours\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        for c in contours:\n",
    "            rect = cv2.boundingRect(c)\n",
    "            height, width = img2.shape[:2]            \n",
    "            if rect[2] > 0.2*height and rect[2] < 0.7*height and rect[3] > 0.2*width and rect[3] < 0.7*width: \n",
    "                x,y,w,h = cv2.boundingRect(c)            # get bounding box of largest contour\n",
    "                img2 = cv2.drawContours(img2, c, -1, color, thickness)\n",
    "                img5 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "            else:\n",
    "                img5=img2\n",
    "    else:\n",
    "        img5=img2\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Motion Detection by Image Difference',img2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "folder = './'\n",
    "face_casc = cv2.CascadeClassifier(folder+'haarcascade_frontalface_default.xml')\n",
    "eye_casc=cv2.CascadeClassifier(folder+'haarcascade_eye.xml')\n",
    "\n",
    "color=(0,255,0)\n",
    "thickness=3\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    faces = face_casc.detectMultiScale(gray, scaleFactor=1.1,minNeighbors=3)\n",
    "    \n",
    "    img=frame                     # default if face is not found\n",
    "    for(x,y,w,h) in faces:\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        #img=cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness) # box for face\n",
    "        eyes=eye_casc.detectMultiScale(roi_gray)\n",
    "        for(x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center=(int(x_eye+0.5*w_eye),int(y_eye+0.5*h_eye))\n",
    "            radius=int(0.3*(w_eye+h_eye))\n",
    "            img=cv2.circle(roi_color,center,radius,color,thickness)\n",
    "            #img=cv2.circle(frame,center,radius,color,thickness)\n",
    "\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Face Detection Harr',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=1\n",
    "isFirstTime=True\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # create background    \n",
    "    if isFirstTime==True:\n",
    "       bg_img=frame\n",
    "       isFirstTime=False\n",
    "    else:\n",
    "       bg_img = dst = cv2.addWeighted(frame,(1-alpha),bg_img,alpha,0)\n",
    "    # the above code is the same as:\n",
    "    fgmask = bg_img+frame\n",
    "    \n",
    "    # create foreground\n",
    "    fg_img=cv2.subtract(frame,bg_img)\n",
    "#     fg_img = cv2.absdiff(frame,bg_img)  \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',frame)\n",
    "    cv2.imshow('Background',bg_img)\n",
    "    cv2.imshow('Foreground',fgmask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
