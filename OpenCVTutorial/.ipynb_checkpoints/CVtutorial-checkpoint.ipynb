{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Tutorial\n",
    "Open CV Tutorial for processing video and images \\\n",
    "Code contains some command of openCV and implementation of readymade blocks from some blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "print( cv2.__version__ )\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing video from webcam and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[ 3  5  5]\n",
      "  [ 3  5  5]\n",
      "  [ 7  3  6]\n",
      "  ...\n",
      "  [10  6 11]\n",
      "  [10  6 11]\n",
      "  [10  6 11]]\n",
      "\n",
      " [[ 3  5  5]\n",
      "  [ 3  5  5]\n",
      "  [ 7  3  6]\n",
      "  ...\n",
      "  [10  5 13]\n",
      "  [10  6 11]\n",
      "  [10  6 11]]\n",
      "\n",
      " [[ 3  5  5]\n",
      "  [ 3  5  5]\n",
      "  [ 3  5  5]\n",
      "  ...\n",
      "  [11  6 14]\n",
      "  [11  7 13]\n",
      "  [11  7 13]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5  6 10]\n",
      "  [ 5  6 10]\n",
      "  [ 9  4 12]\n",
      "  ...\n",
      "  [ 7  9 11]\n",
      "  [ 7  9 11]\n",
      "  [ 7  9 11]]\n",
      "\n",
      " [[ 8  3 11]\n",
      "  [ 8  3 11]\n",
      "  [ 9  4 12]\n",
      "  ...\n",
      "  [ 7  9 11]\n",
      "  [ 7  9 11]\n",
      "  [ 8 10 12]]\n",
      "\n",
      " [[ 9  5 10]\n",
      "  [ 9  5 10]\n",
      "  [ 9  5 10]\n",
      "  ...\n",
      "  [11  6 16]\n",
      "  [ 7  8 13]\n",
      "  [ 7  8 13]]]\n",
      "ret True\n",
      "[[[ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  [ 8  5  7]\n",
      "  ...\n",
      "  [ 8 25 22]\n",
      "  [10 27 17]\n",
      "  [ 9 26 16]]\n",
      "\n",
      " [[ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [13 28 26]\n",
      "  [10 29 21]\n",
      "  [10 29 21]]\n",
      "\n",
      " [[ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [15 32 29]\n",
      "  [12 32 26]\n",
      "  [ 9 30 24]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5 18 21]\n",
      "  [ 7 19 22]\n",
      "  [ 8 21 23]\n",
      "  ...\n",
      "  [15 27 32]\n",
      "  [16 25 30]\n",
      "  [14 24 29]]\n",
      "\n",
      " [[ 7 19 23]\n",
      "  [ 5 17 22]\n",
      "  [ 9 19 22]\n",
      "  ...\n",
      "  [18 27 34]\n",
      "  [17 25 33]\n",
      "  [16 24 32]]\n",
      "\n",
      " [[ 6 21 23]\n",
      "  [ 4 20 22]\n",
      "  [ 7 18 21]\n",
      "  ...\n",
      "  [17 25 35]\n",
      "  [14 23 31]\n",
      "  [13 22 30]]]\n",
      "ret True\n",
      "[[[ 9  6  9]\n",
      "  [10  7 10]\n",
      "  [ 6  9  8]\n",
      "  ...\n",
      "  [13 23 28]\n",
      "  [13 23 21]\n",
      "  [ 9 19 17]]\n",
      "\n",
      " [[ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  [ 5  7  7]\n",
      "  ...\n",
      "  [13 23 28]\n",
      "  [13 23 21]\n",
      "  [12 21 20]]\n",
      "\n",
      " [[ 7  3  8]\n",
      "  [ 8  4  9]\n",
      "  [ 5  7  7]\n",
      "  ...\n",
      "  [12 24 29]\n",
      "  [13 24 25]\n",
      "  [10 21 21]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5 19 19]\n",
      "  [ 5 19 19]\n",
      "  [ 9 18 19]\n",
      "  ...\n",
      "  [16 25 30]\n",
      "  [18 25 30]\n",
      "  [18 25 30]]\n",
      "\n",
      " [[ 7 19 19]\n",
      "  [ 7 19 19]\n",
      "  [ 9 18 19]\n",
      "  ...\n",
      "  [16 24 32]\n",
      "  [19 26 32]\n",
      "  [19 26 32]]\n",
      "\n",
      " [[ 7 18 21]\n",
      "  [ 7 18 21]\n",
      "  [ 9 17 21]\n",
      "  ...\n",
      "  [20 26 34]\n",
      "  [21 25 33]\n",
      "  [21 25 33]]]\n",
      "ret True\n",
      "[[[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [16 24 29]\n",
      "  [14 24 29]\n",
      "  [16 25 30]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [16 25 30]\n",
      "  [16 25 30]\n",
      "  [16 25 30]]\n",
      "\n",
      " [[ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  [ 9  6  9]\n",
      "  ...\n",
      "  [14 24 29]\n",
      "  [14 24 29]\n",
      "  [16 25 30]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 7 16 24]\n",
      "  [ 9 17 25]\n",
      "  [ 9 18 23]\n",
      "  ...\n",
      "  [19 26 32]\n",
      "  [17 26 32]\n",
      "  [17 26 32]]\n",
      "\n",
      " [[ 7 16 24]\n",
      "  [ 7 16 24]\n",
      "  [ 9 18 23]\n",
      "  ...\n",
      "  [21 26 32]\n",
      "  [19 25 33]\n",
      "  [19 25 33]]\n",
      "\n",
      " [[ 9 18 23]\n",
      "  [ 7 17 22]\n",
      "  [ 9 17 22]\n",
      "  ...\n",
      "  [25 27 35]\n",
      "  [24 25 34]\n",
      "  [24 25 34]]]\n",
      "ret True\n",
      "[[[12 14 16]\n",
      "  [13 15 17]\n",
      "  [13 16 15]\n",
      "  ...\n",
      "  [44 60 60]\n",
      "  [42 59 56]\n",
      "  [39 56 54]]\n",
      "\n",
      " [[10 14 16]\n",
      "  [11 15 17]\n",
      "  [13 16 15]\n",
      "  ...\n",
      "  [46 63 65]\n",
      "  [47 59 64]\n",
      "  [44 56 61]]\n",
      "\n",
      " [[ 8 14 16]\n",
      "  [ 9 15 17]\n",
      "  [13 16 15]\n",
      "  ...\n",
      "  [48 64 70]\n",
      "  [49 62 69]\n",
      "  [48 61 68]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[34 52 52]\n",
      "  [35 54 53]\n",
      "  [39 53 53]\n",
      "  ...\n",
      "  [62 62 69]\n",
      "  [60 63 67]\n",
      "  [59 62 66]]\n",
      "\n",
      " [[34 53 50]\n",
      "  [34 53 50]\n",
      "  [39 54 51]\n",
      "  ...\n",
      "  [68 63 73]\n",
      "  [64 66 68]\n",
      "  [64 66 68]]\n",
      "\n",
      " [[35 54 51]\n",
      "  [34 53 50]\n",
      "  [37 54 51]\n",
      "  ...\n",
      "  [73 67 79]\n",
      "  [70 63 75]\n",
      "  [70 63 75]]]\n",
      "ret True\n",
      "[[[12 14 14]\n",
      "  [13 16 15]\n",
      "  [12 17 16]\n",
      "  ...\n",
      "  [40 61 67]\n",
      "  [46 60 60]\n",
      "  [41 55 55]]\n",
      "\n",
      " [[10 15 14]\n",
      "  [10 15 14]\n",
      "  [13 16 15]\n",
      "  ...\n",
      "  [46 62 66]\n",
      "  [48 61 64]\n",
      "  [46 59 61]]\n",
      "\n",
      " [[ 9 14 13]\n",
      "  [10 15 14]\n",
      "  [13 16 15]\n",
      "  ...\n",
      "  [49 62 69]\n",
      "  [48 61 68]\n",
      "  [46 60 67]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[36 50 55]\n",
      "  [36 50 55]\n",
      "  [36 50 55]\n",
      "  ...\n",
      "  [55 63 66]\n",
      "  [53 62 68]\n",
      "  [53 62 68]]\n",
      "\n",
      " [[37 49 54]\n",
      "  [38 50 55]\n",
      "  [36 50 55]\n",
      "  ...\n",
      "  [64 64 71]\n",
      "  [57 64 70]\n",
      "  [56 63 69]]\n",
      "\n",
      " [[37 49 54]\n",
      "  [38 50 55]\n",
      "  [38 50 55]\n",
      "  ...\n",
      "  [68 69 73]\n",
      "  [63 67 73]\n",
      "  [63 67 73]]]\n",
      "ret True\n",
      "[[[14 21 27]\n",
      "  [16 24 29]\n",
      "  [16 25 30]\n",
      "  ...\n",
      "  [56 73 70]\n",
      "  [58 74 67]\n",
      "  [54 70 63]]\n",
      "\n",
      " [[14 21 27]\n",
      "  [15 22 28]\n",
      "  [14 24 29]\n",
      "  ...\n",
      "  [54 78 74]\n",
      "  [57 76 73]\n",
      "  [54 73 70]]\n",
      "\n",
      " [[13 17 25]\n",
      "  [15 19 27]\n",
      "  [15 22 28]\n",
      "  ...\n",
      "  [59 82 81]\n",
      "  [56 82 78]\n",
      "  [56 82 78]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[44 68 64]\n",
      "  [45 69 65]\n",
      "  [51 66 68]\n",
      "  ...\n",
      "  [75 74 83]\n",
      "  [75 76 80]\n",
      "  [74 74 79]]\n",
      "\n",
      " [[43 69 65]\n",
      "  [43 69 65]\n",
      "  [48 66 66]\n",
      "  ...\n",
      "  [79 79 88]\n",
      "  [77 80 86]\n",
      "  [76 79 85]]\n",
      "\n",
      " [[41 70 65]\n",
      "  [40 69 64]\n",
      "  [47 64 66]\n",
      "  ...\n",
      "  [88 82 93]\n",
      "  [83 82 91]\n",
      "  [82 81 90]]]\n",
      "ret True\n",
      "[[[17 17 23]\n",
      "  [22 22 29]\n",
      "  [22 26 26]\n",
      "  ...\n",
      "  [45 75 73]\n",
      "  [42 75 67]\n",
      "  [41 73 66]]\n",
      "\n",
      " [[14 13 24]\n",
      "  [19 17 29]\n",
      "  [18 25 26]\n",
      "  ...\n",
      "  [48 75 75]\n",
      "  [52 72 73]\n",
      "  [52 72 73]]\n",
      "\n",
      " [[12 15 21]\n",
      "  [17 19 26]\n",
      "  [19 23 25]\n",
      "  ...\n",
      "  [54 76 79]\n",
      "  [56 76 78]\n",
      "  [56 76 78]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[47 64 68]\n",
      "  [48 65 69]\n",
      "  [52 66 66]\n",
      "  ...\n",
      "  [76 84 87]\n",
      "  [72 79 85]\n",
      "  [69 76 82]]\n",
      "\n",
      " [[45 64 68]\n",
      "  [45 64 68]\n",
      "  [51 63 68]\n",
      "  ...\n",
      "  [84 89 88]\n",
      "  [78 87 88]\n",
      "  [75 83 84]]\n",
      "\n",
      " [[47 64 68]\n",
      "  [47 64 68]\n",
      "  [49 63 68]\n",
      "  ...\n",
      "  [89 91 91]\n",
      "  [87 92 91]\n",
      "  [84 89 88]]]\n",
      "ret True\n",
      "[[[24 35 35]\n",
      "  [27 38 39]\n",
      "  [32 40 41]\n",
      "  ...\n",
      "  [62 91 86]\n",
      "  [62 91 86]\n",
      "  [64 93 88]]\n",
      "\n",
      " [[18 31 33]\n",
      "  [22 34 37]\n",
      "  [22 39 36]\n",
      "  ...\n",
      "  [66 90 86]\n",
      "  [73 91 86]\n",
      "  [74 92 87]]\n",
      "\n",
      " [[15 30 32]\n",
      "  [17 33 35]\n",
      "  [18 35 33]\n",
      "  ...\n",
      "  [71 90 87]\n",
      "  [77 89 87]\n",
      "  [77 89 87]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[49 81 80]\n",
      "  [46 78 78]\n",
      "  [55 79 80]\n",
      "  ...\n",
      "  [80 89 94]\n",
      "  [81 89 97]\n",
      "  [77 86 94]]\n",
      "\n",
      " [[43 82 76]\n",
      "  [43 82 76]\n",
      "  [55 80 78]\n",
      "  ...\n",
      "  [79 83 91]\n",
      "  [78 87 95]\n",
      "  [80 88 96]]\n",
      "\n",
      " [[47 87 76]\n",
      "  [45 85 74]\n",
      "  [55 81 77]\n",
      "  ...\n",
      "  [77 79 88]\n",
      "  [81 85 94]\n",
      "  [84 88 96]]]\n",
      "ret True\n",
      "[[[27 30 36]\n",
      "  [30 32 39]\n",
      "  [28 32 39]\n",
      "  ...\n",
      "  [65 89 92]\n",
      "  [66 91 92]\n",
      "  [66 91 92]]\n",
      "\n",
      " [[22 23 39]\n",
      "  [27 28 44]\n",
      "  [30 33 37]\n",
      "  ...\n",
      "  [71 88 92]\n",
      "  [68 92 88]\n",
      "  [68 92 88]]\n",
      "\n",
      " [[17 20 33]\n",
      "  [21 23 36]\n",
      "  [28 28 35]\n",
      "  ...\n",
      "  [72 86 91]\n",
      "  [73 88 90]\n",
      "  [74 90 92]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[50 78 76]\n",
      "  [50 78 76]\n",
      "  [49 82 74]\n",
      "  ...\n",
      "  [78 91 91]\n",
      "  [79 93 91]\n",
      "  [78 92 90]]\n",
      "\n",
      " [[48 79 76]\n",
      "  [48 79 76]\n",
      "  [53 80 76]\n",
      "  ...\n",
      "  [72 79 87]\n",
      "  [74 83 90]\n",
      "  [75 84 91]]\n",
      "\n",
      " [[50 79 74]\n",
      "  [50 79 74]\n",
      "  [57 81 77]\n",
      "  ...\n",
      "  [70 68 82]\n",
      "  [73 73 86]\n",
      "  [77 77 91]]]\n",
      "ret True\n",
      "[[[ 39  35  40]\n",
      "  [ 45  41  46]\n",
      "  [ 42  45  44]\n",
      "  ...\n",
      "  [ 80 106  97]\n",
      "  [ 85 102  97]\n",
      "  [ 87 105 100]]\n",
      "\n",
      " [[ 36  32  37]\n",
      "  [ 43  39  44]\n",
      "  [ 45  42  45]\n",
      "  ...\n",
      "  [ 87 105 100]\n",
      "  [ 87 106  98]\n",
      "  [ 86 104  97]]\n",
      "\n",
      " [[ 33  29  35]\n",
      "  [ 40  36  42]\n",
      "  [ 41  42  38]\n",
      "  ...\n",
      "  [ 94 106 102]\n",
      "  [ 95 108 102]\n",
      "  [ 97 111 104]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 81  97  90]\n",
      "  [ 82  98  91]\n",
      "  [ 84  99  89]\n",
      "  ...\n",
      "  [ 96 104 101]\n",
      "  [ 93 110  98]\n",
      "  [ 89 107  95]]\n",
      "\n",
      " [[ 81 101  89]\n",
      "  [ 79  99  87]\n",
      "  [ 81  98  88]\n",
      "  ...\n",
      "  [ 89  98  97]\n",
      "  [ 82 104 100]\n",
      "  [ 82 104 100]]\n",
      "\n",
      " [[ 80 104  89]\n",
      "  [ 78 101  86]\n",
      "  [ 80  97  87]\n",
      "  ...\n",
      "  [ 84  88  92]\n",
      "  [ 84  95  97]\n",
      "  [ 87  97 100]]]\n",
      "ret True\n",
      "[[[ 40  36  42]\n",
      "  [ 44  40  45]\n",
      "  [ 42  43  40]\n",
      "  ...\n",
      "  [ 92 111 101]\n",
      "  [ 94 110 103]\n",
      "  [ 93 109 102]]\n",
      "\n",
      " [[ 38  40  40]\n",
      "  [ 36  39  38]\n",
      "  [ 39  35  40]\n",
      "  ...\n",
      "  [ 95 111 104]\n",
      "  [ 96 109 104]\n",
      "  [ 96 109 104]]\n",
      "\n",
      " [[ 36  30  40]\n",
      "  [ 37  31  41]\n",
      "  [ 38  32  42]\n",
      "  ...\n",
      "  [ 96 111 107]\n",
      "  [ 97 110 105]\n",
      "  [ 97 110 105]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78 100  89]\n",
      "  [ 78 100  89]\n",
      "  [ 80  99  89]\n",
      "  ...\n",
      "  [ 88  92  85]\n",
      "  [ 88  95  94]\n",
      "  [ 91  98  97]]\n",
      "\n",
      " [[ 82  98  91]\n",
      "  [ 82  98  91]\n",
      "  [ 80  99  91]\n",
      "  ...\n",
      "  [ 72  73  71]\n",
      "  [ 73  77  78]\n",
      "  [ 79  83  84]]\n",
      "\n",
      " [[ 82  97  93]\n",
      "  [ 82  97  93]\n",
      "  [ 82  98  91]\n",
      "  ...\n",
      "  [ 73  63  67]\n",
      "  [ 78  62  70]\n",
      "  [ 80  64  71]]]\n",
      "ret True\n",
      "[[[ 44  49  48]\n",
      "  [ 46  51  50]\n",
      "  [ 43  54  50]\n",
      "  ...\n",
      "  [100 119 109]\n",
      "  [102 118 111]\n",
      "  [102 118 111]]\n",
      "\n",
      " [[ 45  47  47]\n",
      "  [ 47  49  49]\n",
      "  [ 44  51  50]\n",
      "  ...\n",
      "  [101 120 110]\n",
      "  [102 119 109]\n",
      "  [102 119 109]]\n",
      "\n",
      " [[ 47  41  45]\n",
      "  [ 52  46  49]\n",
      "  [ 47  50  47]\n",
      "  ...\n",
      "  [101 120 110]\n",
      "  [101 120 110]\n",
      "  [101 120 110]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78 108 101]\n",
      "  [ 78 108 101]\n",
      "  [ 80 109  98]\n",
      "  ...\n",
      "  [ 94 116 117]\n",
      "  [ 98 119 111]\n",
      "  [ 98 119 111]]\n",
      "\n",
      " [[ 76 108 101]\n",
      "  [ 76 108 101]\n",
      "  [ 80 108  99]\n",
      "  ...\n",
      "  [ 89 100 108]\n",
      "  [ 92 108 108]\n",
      "  [ 94 110 110]]\n",
      "\n",
      " [[ 79 110 105]\n",
      "  [ 79 110 105]\n",
      "  [ 81 109 102]\n",
      "  ...\n",
      "  [ 92  91 101]\n",
      "  [ 94  99  98]\n",
      "  [ 98 103 102]]]\n",
      "ret True\n",
      "[[[ 47  47  45]\n",
      "  [ 50  51  48]\n",
      "  [ 52  56  46]\n",
      "  ...\n",
      "  [105 120 109]\n",
      "  [100 123 110]\n",
      "  [100 123 110]]\n",
      "\n",
      " [[ 45  46  44]\n",
      "  [ 49  50  47]\n",
      "  [ 50  52  45]\n",
      "  ...\n",
      "  [108 120 113]\n",
      "  [105 123 111]\n",
      "  [105 123 111]]\n",
      "\n",
      " [[ 42  43  40]\n",
      "  [ 45  46  44]\n",
      "  [ 48  49  45]\n",
      "  ...\n",
      "  [111 122 116]\n",
      "  [107 123 116]\n",
      "  [107 123 116]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 75 109 104]\n",
      "  [ 77 110 105]\n",
      "  [ 76 108 102]\n",
      "  ...\n",
      "  [105 122 117]\n",
      "  [100 125 118]\n",
      "  [ 99 123 117]]\n",
      "\n",
      " [[ 74 111 105]\n",
      "  [ 73 109 104]\n",
      "  [ 75 109 104]\n",
      "  ...\n",
      "  [ 99 116 113]\n",
      "  [ 96 120 116]\n",
      "  [ 96 120 116]]\n",
      "\n",
      " [[ 77 111 103]\n",
      "  [ 75 110 102]\n",
      "  [ 76 108 101]\n",
      "  ...\n",
      "  [ 95 109 107]\n",
      "  [ 98 115 110]\n",
      "  [ 99 116 111]]]\n",
      "ret True\n",
      "[[[ 48  60  51]\n",
      "  [ 50  62  53]\n",
      "  [ 54  65  54]\n",
      "  ...\n",
      "  [115 128 117]\n",
      "  [118 126 116]\n",
      "  [118 126 116]]\n",
      "\n",
      " [[ 45  57  50]\n",
      "  [ 49  60  54]\n",
      "  [ 51  64  53]\n",
      "  ...\n",
      "  [115 127 120]\n",
      "  [119 126 120]\n",
      "  [119 126 120]]\n",
      "\n",
      " [[ 45  53  50]\n",
      "  [ 50  58  54]\n",
      "  [ 51  61  52]\n",
      "  ...\n",
      "  [120 128 124]\n",
      "  [123 127 121]\n",
      "  [124 128 123]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 90 121 102]\n",
      "  [ 90 121 102]\n",
      "  [ 98 119 104]\n",
      "  ...\n",
      "  [108 125 122]\n",
      "  [111 123 121]\n",
      "  [112 124 122]]\n",
      "\n",
      " [[ 90 121 102]\n",
      "  [ 91 122 103]\n",
      "  [ 96 120 102]\n",
      "  ...\n",
      "  [112 121 120]\n",
      "  [110 122 120]\n",
      "  [110 122 120]]\n",
      "\n",
      " [[ 91 123 102]\n",
      "  [ 91 123 102]\n",
      "  [ 97 121 103]\n",
      "  ...\n",
      "  [114 118 118]\n",
      "  [113 120 119]\n",
      "  [114 121 120]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[ 46  54  52]\n",
      "  [ 49  56  55]\n",
      "  [ 53  58  57]\n",
      "  ...\n",
      "  [105 128 122]\n",
      "  [110 126 119]\n",
      "  [110 126 119]]\n",
      "\n",
      " [[ 49  52  51]\n",
      "  [ 52  54  54]\n",
      "  [ 53  55  55]\n",
      "  ...\n",
      "  [112 128 123]\n",
      "  [112 126 119]\n",
      "  [113 127 120]]\n",
      "\n",
      " [[ 47  49  49]\n",
      "  [ 49  52  51]\n",
      "  [ 54  51  54]\n",
      "  ...\n",
      "  [114 129 124]\n",
      "  [116 130 121]\n",
      "  [117 131 122]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 98 114 109]\n",
      "  [ 98 114 109]\n",
      "  [103 112 111]\n",
      "  ...\n",
      "  [110 128 123]\n",
      "  [111 127 122]\n",
      "  [111 127 122]]\n",
      "\n",
      " [[100 113 109]\n",
      "  [ 99 112 108]\n",
      "  [102 109 108]\n",
      "  ...\n",
      "  [111 126 123]\n",
      "  [111 126 123]\n",
      "  [110 125 122]]\n",
      "\n",
      " [[100 111 107]\n",
      "  [100 111 107]\n",
      "  [104 110 107]\n",
      "  ...\n",
      "  [116 121 118]\n",
      "  [112 121 120]\n",
      "  [112 121 120]]]\n",
      "ret True\n",
      "[[[ 59  56  59]\n",
      "  [ 63  59  62]\n",
      "  [ 62  63  60]\n",
      "  ...\n",
      "  [124 133 127]\n",
      "  [126 134 126]\n",
      "  [126 134 126]]\n",
      "\n",
      " [[ 59  56  59]\n",
      "  [ 63  59  62]\n",
      "  [ 61  61  59]\n",
      "  ...\n",
      "  [125 135 131]\n",
      "  [125 135 131]\n",
      "  [123 134 130]]\n",
      "\n",
      " [[ 57  55  53]\n",
      "  [ 61  60  58]\n",
      "  [ 58  60  55]\n",
      "  ...\n",
      "  [124 137 132]\n",
      "  [121 136 131]\n",
      "  [121 136 131]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 99 128 108]\n",
      "  [ 99 128 108]\n",
      "  [106 128 110]\n",
      "  ...\n",
      "  [119 135 133]\n",
      "  [121 136 131]\n",
      "  [121 136 131]]\n",
      "\n",
      " [[101 125 114]\n",
      "  [101 125 114]\n",
      "  [105 124 114]\n",
      "  ...\n",
      "  [119 135 133]\n",
      "  [119 136 131]\n",
      "  [119 136 131]]\n",
      "\n",
      " [[105 122 117]\n",
      "  [105 122 117]\n",
      "  [107 122 117]\n",
      "  ...\n",
      "  [117 132 129]\n",
      "  [117 132 129]\n",
      "  [117 132 129]]]\n",
      "ret True\n",
      "[[[ 54  56  56]\n",
      "  [ 59  61  61]\n",
      "  [ 62  65  62]\n",
      "  ...\n",
      "  [123 131 128]\n",
      "  [127 134 121]\n",
      "  [128 135 122]]\n",
      "\n",
      " [[ 50  54  54]\n",
      "  [ 53  58  57]\n",
      "  [ 54  59  58]\n",
      "  ...\n",
      "  [129 134 131]\n",
      "  [131 136 126]\n",
      "  [132 138 127]]\n",
      "\n",
      " [[ 49  52  50]\n",
      "  [ 53  56  53]\n",
      "  [ 52  57  54]\n",
      "  ...\n",
      "  [130 135 132]\n",
      "  [132 136 131]\n",
      "  [134 138 133]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[108 125 115]\n",
      "  [108 125 115]\n",
      "  [110 124 115]\n",
      "  ...\n",
      "  [115 137 131]\n",
      "  [115 137 131]\n",
      "  [115 137 131]]\n",
      "\n",
      " [[107 124 114]\n",
      "  [107 124 114]\n",
      "  [112 124 115]\n",
      "  ...\n",
      "  [119 136 131]\n",
      "  [119 136 131]\n",
      "  [119 136 131]]\n",
      "\n",
      " [[111 122 116]\n",
      "  [111 122 116]\n",
      "  [113 122 114]\n",
      "  ...\n",
      "  [120 132 130]\n",
      "  [120 132 130]\n",
      "  [120 132 130]]]\n",
      "ret True\n",
      "[[[ 69  57  61]\n",
      "  [ 71  58  62]\n",
      "  [ 72  59  63]\n",
      "  ...\n",
      "  [129 137 126]\n",
      "  [127 137 122]\n",
      "  [127 137 122]]\n",
      "\n",
      " [[ 68  55  60]\n",
      "  [ 71  58  62]\n",
      "  [ 68  61  60]\n",
      "  ...\n",
      "  [130 137 129]\n",
      "  [130 139 126]\n",
      "  [129 138 125]]\n",
      "\n",
      " [[ 66  53  57]\n",
      "  [ 69  57  61]\n",
      "  [ 65  61  59]\n",
      "  ...\n",
      "  [130 137 129]\n",
      "  [129 137 126]\n",
      "  [129 137 126]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[103 126 118]\n",
      "  [104 127 119]\n",
      "  [110 128 116]\n",
      "  ...\n",
      "  [128 141 137]\n",
      "  [129 140 136]\n",
      "  [128 139 135]]\n",
      "\n",
      " [[102 129 117]\n",
      "  [101 127 116]\n",
      "  [109 127 115]\n",
      "  ...\n",
      "  [124 139 136]\n",
      "  [127 140 136]\n",
      "  [126 139 135]]\n",
      "\n",
      " [[103 126 118]\n",
      "  [104 127 119]\n",
      "  [110 128 116]\n",
      "  ...\n",
      "  [125 137 135]\n",
      "  [126 139 135]\n",
      "  [125 138 133]]]\n",
      "ret True\n",
      "[[[ 61  67  55]\n",
      "  [ 62  68  56]\n",
      "  [ 61  66  58]\n",
      "  ...\n",
      "  [131 135 130]\n",
      "  [126 138 129]\n",
      "  [126 138 129]]\n",
      "\n",
      " [[ 56  64  56]\n",
      "  [ 56  64  56]\n",
      "  [ 59  60  58]\n",
      "  ...\n",
      "  [132 135 132]\n",
      "  [130 135 132]\n",
      "  [130 135 132]]\n",
      "\n",
      " [[ 54  57  54]\n",
      "  [ 57  61  58]\n",
      "  [ 63  59  62]\n",
      "  ...\n",
      "  [133 136 133]\n",
      "  [132 138 135]\n",
      "  [133 139 136]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[105 128 122]\n",
      "  [105 128 122]\n",
      "  [105 129 120]\n",
      "  ...\n",
      "  [124 139 135]\n",
      "  [125 139 132]\n",
      "  [124 137 131]]\n",
      "\n",
      " [[108 126 121]\n",
      "  [108 126 121]\n",
      "  [109 128 120]\n",
      "  ...\n",
      "  [123 138 133]\n",
      "  [124 137 132]\n",
      "  [124 137 132]]\n",
      "\n",
      " [[107 125 119]\n",
      "  [107 125 119]\n",
      "  [104 127 121]\n",
      "  ...\n",
      "  [130 135 132]\n",
      "  [129 134 131]\n",
      "  [129 134 131]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0\n",
    "frames = 20\n",
    "while(count < frames):\n",
    "    count += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    print('ret',ret)\n",
    "    print(frame)\n",
    "    # Our operations on the frame come here    \n",
    "    img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(img,0)     # flip up-down\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record and Save the Video from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create writer object\n",
    "fileName='out.avi'  # change the file name if needed\n",
    "imgSize=(640,480)\n",
    "frame_per_second=30.0\n",
    "writer = cv2.VideoWriter(fileName, cv2.VideoWriter_fourcc(*\"MJPG\"), frame_per_second,imgSize)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "start_time = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        writer.write(frame)                   # save the frame into video file\n",
    "        cv2.imshow('Video Capture',frame)     # show on the screen\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # press q to Quit, where? : In video window\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the video and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='out.avi'  # change the file name if needed\n",
    "\n",
    "cap = cv2.VideoCapture(fileName)          # load the video\n",
    "while(cap.isOpened()):                    # play the video by reading frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        # optional: do some image processing here \n",
    "        cv2.imshow('frame',frame)              # show the video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the recording window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factorx=0.5\n",
    "scaling_factory=0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # set frame size (e.g. 640x480; 320x240; 960x720), larger is slower    \n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_WIDTH,320)\n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_HEIGHT,240)\n",
    "    frame=cv2.resize(frame,None,fx=scaling_factorx,fy=scaling_factory,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    img = frame\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Smaller Window',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-njn2fp78/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-918111990c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HLS)   # RGB color to HLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HLS)   # BGR color to HLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2XYZ\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# RGB color to CIE XYZ.Rec 709\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2XYZ)   # RGB color to CIE XYZ.Rec 709\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2Lab)   # BGR color to CIE L\\*a\\*b\\*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-njn2fp78/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "### Colour Transformation\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR color to RGB\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # RGB color to BGR\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)  # RGB color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)   # BGR color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HSV)   # RGB color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HLS)   # RGB color to HLS\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HLS)   # BGR color to HLS\n",
    "    img = cv2.cvtColor(frame,cv2.COLOR_BGR2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2Lab)   # BGR color to CIE L\\*a\\*b\\*\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2Luv)   # RGB color to CIE L\\*u\\*v\\*\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Gray',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Enhancement\n",
    "\n",
    "Change the contrast of image using Histogram equalization. \\\n",
    "command : equalizeHist() -- only for gray scale image \\\n",
    "\n",
    "Ref : https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = frame\n",
    "    img = equalizeHistColor(frame)\n",
    "    \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Histogram Equalization',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def WarpImage(frame):\n",
    "    ax,bx=10.0,100\n",
    "    ay,by=20.0,120\n",
    "    img=np.zeros(frame.shape,dtype=frame.dtype)\n",
    "    rows,cols=img.shape[:2]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x=int(ax*math.sin(2*math.pi*i/bx))\n",
    "            offset_y=int(ay*math.cos(2*math.pi*j/by))\n",
    "            if i+offset_y<rows and j+offset_x<cols:\n",
    "                img[i,j]=frame[(i+offset_y)%rows,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img[i,j]=0\n",
    "    return img\n",
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() \n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    if ret==1:\n",
    "        #img = WarpImage(frame)\n",
    "        img = equalizeHistColor(WarpImage(frame))\n",
    "    else:\n",
    "        img = equalizeHistColor(frame)\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Warped',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=5\n",
    "parameter2=20\n",
    "intApertureSize=10\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    ## Smoothening Filters   \n",
    "    frame = cv2.GaussianBlur(frame, (kernelSize,kernelSize),0,0) # Gaussian Blur smoothing filter\n",
    "#     frame = cv2.medianBlur(frame, kernelSize) # Median Blur smoothing filter\n",
    "#     frame = cv2.blur(frame,(kernelSize,kernelSize)) # Average Blur smoothing filter\n",
    "#     frame = cv2.bilateralFilter(frame,9,75,75) # Bilateral Filter for smoothing filter\n",
    "    \n",
    "    ## Edge Detection Algorithm\n",
    "    frame = cv2.Canny(frame,parameter1,parameter2,intApertureSize) # Canny edge detection\n",
    "    frame = cv2.Laplacian(frame,cv2.CV_64F) # Laplacian edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=kernelSize) # X-direction Sobel edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=kernelSize) # Y-direction Sobel edge detection\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Canny',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Impose\n",
    "\n",
    "- edge detection as mask\n",
    "- superimpose it with the original image\n",
    "- Processing : reverse the edge detection result using bitwise Not to inverse it. Then, use bitwise and to superimpose with the blur image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=10\n",
    "parameter2=40\n",
    "intApertureSize=1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame1 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    frame = cv2.GaussianBlur(frame1, (kernelSize,kernelSize), 0, 0) \n",
    "    edge = cv2.Canny(frame,parameter1,parameter2,intApertureSize)  # Canny edge detection\n",
    "    mask_edge = cv2.bitwise_not(edge)\n",
    "    frame = cv2.bitwise_and(frame1,frame1,mask = mask_edge)   \n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Super Impose',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countour\n",
    "\n",
    "Functions:\n",
    "    - img, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,chainRuleApproximation)\n",
    "    - img=cv2.drawContours(img, contours, index, colorTuple, thickness)\n",
    "\n",
    "Arguments:\n",
    "    - img = image\n",
    "    - index=-1 means show all contours, 0-len(contours) means to show each contour\n",
    "    - chainRuleApproximation is either:\n",
    "        - cv2.CHAIN_APPROX_SIMPLE: to give only 4 points in a rectangle\n",
    "        - cv2.CHAIN_APPROX_NONE: to give all points\n",
    "    - colorTuple is any BGR color. For instance:\n",
    "        - (255,0,0) for Blue\n",
    "        - (0,255,0) for Green\n",
    "        - (0,0,255) for Red\n",
    "    - thickness is integer 1-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(gray,10,20,cv2.THRESH_BINARY_INV)\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)   \n",
    "    if len(contours) != 0:\n",
    "            c = max(contours, key = cv2.contourArea) # find the largest contour\n",
    "            x,y,w,h = cv2.boundingRect(c)          # get bounding box of largest contour\n",
    "            #img2=cv2.drawContours(frame, c, -1, color, thickness) # draw largest contour\n",
    "            img2 = cv2.drawContours(frame, contours, -1, color, thickness) # draw all contours\n",
    "            img3 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "\n",
    "    # Display the resulting image\n",
    "#     cv2.imshow('Contour',img3)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "-Generate mask using thresold. A mask is a binary image.\n",
    "\n",
    "Adaptive threshold has the following parameters:\n",
    "\n",
    "   - src – Source 8-bit single-channel image.\n",
    "   - dst – Destination image of the same size and the same type as src .\n",
    "   - maxValue – Non-zero value assigned to the pixels for which the condition is satisfied. Put 255.\n",
    "   - adaptiveMethod – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C .\n",
    "   - thresholdType – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV .\n",
    "   - blockSize – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "   - C – Constant subtracted from the mean or weighted mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "threshold1=100\n",
    "threshold2=200\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # equalize the histogram of color image\n",
    "    frame1 = equalizeHistColor(frame) \n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "     \n",
    "    ## Thresolding Method\n",
    "    ret, mask = cv2.threshold(blur, threshold1, threshold2, cv2.THRESH_BINARY)\n",
    "    ret, mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #ret, mask = cv2.threshold(blur,threshold1, threshold2,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    #mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((3, 3), np.uint8)  \n",
    "    mask=cv2.erode(mask,kernel,iterations=7) # morphology erosion   \n",
    "    mask=cv2.dilate(mask,kernel,iterations=5) # morphology dilation\n",
    "    \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    img = cv2.bitwise_and(frame1,frame1,mask = mask_inv)\n",
    "    img = cv2.addWeighted(frame1,0.1,img,0.9,0)\n",
    "    \n",
    "    #img=mask\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Thresholding-Otsu',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow\n",
    "- shows aura kinda.\n",
    "- motion of image objects between two consecutive frames caused by the movemement of object or camera.\n",
    "Ref : https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_lucas_kanade.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    prvs = next\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Optical Flow Aura',bgr)\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Detection by Image Difference\n",
    "\n",
    "- images are captured with a time delay of 1/25 seconds\n",
    "- After image difference, get the contour out of it \n",
    "- put the bounding box out of the contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cba61c721025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# get bounding box of largest contour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img3' is not defined"
     ]
    }
   ],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture two frames\n",
    "    ret, frame1 = cap.read()  # first image\n",
    "    time.sleep(1/25)          # slight delay\n",
    "    ret, frame2 = cap.read()  # second image \n",
    "    img1 = cv2.absdiff(frame1,frame2)  # image difference\n",
    "    \n",
    "    # get theshold image\n",
    "    gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(blur,200,255,cv2.THRESH_OTSU)\n",
    "    \n",
    "    # combine frame and the image difference\n",
    "    img2 = cv2.addWeighted(frame1,0.9,img1,0.1,0)\n",
    "    \n",
    "    # get contours and set bounding box from contours\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        for c in contours:\n",
    "            rect = cv2.boundingRect(c)\n",
    "            height, width = img3.shape[:2]            \n",
    "            if rect[2] > 0.2*height and rect[2] < 0.7*height and rect[3] > 0.2*width and rect[3] < 0.7*width: \n",
    "                x,y,w,h = cv2.boundingRect(c)            # get bounding box of largest contour\n",
    "                img4=cv2.drawContours(img2, c, -1, color, thickness)\n",
    "                img5 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "            else:\n",
    "                img5=img2\n",
    "    else:\n",
    "        img5=img2\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Motion Detection by Image Difference',img2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "folder = './'\n",
    "face_casc = cv2.CascadeClassifier(folder+'haarcascade_frontalface_default.xml')\n",
    "eye_casc=cv2.CascadeClassifier(folder+'haarcascade_eye.xml')\n",
    "\n",
    "color=(0,255,0)\n",
    "thickness=3\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    faces = face_casc.detectMultiScale(gray, scaleFactor=1.1,minNeighbors=3)\n",
    "    \n",
    "    img=frame                     # default if face is not found\n",
    "    for(x,y,w,h) in faces:\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        #img=cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness) # box for face\n",
    "        eyes=eye_casc.detectMultiScale(roi_gray)\n",
    "        for(x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center=(int(x_eye+0.5*w_eye),int(y_eye+0.5*h_eye))\n",
    "            radius=int(0.3*(w_eye+h_eye))\n",
    "            img=cv2.circle(roi_color,center,radius,color,thickness)\n",
    "            #img=cv2.circle(frame,center,radius,color,thickness)\n",
    "\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Face Detection Harr',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=1\n",
    "isFirstTime=True\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # create background    \n",
    "    if isFirstTime==True:\n",
    "       bg_img=frame\n",
    "       isFirstTime=False\n",
    "    else:\n",
    "       bg_img = dst = cv2.addWeighted(frame,(1-alpha),bg_img,alpha,0)\n",
    "    # the above code is the same as:\n",
    "    fgmask = bg_img+frame\n",
    "    \n",
    "    # create foreground\n",
    "    fg_img=cv2.subtract(frame,bg_img)\n",
    "#     fg_img = cv2.absdiff(frame,bg_img)  \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',frame)\n",
    "    cv2.imshow('Background',bg_img)\n",
    "    cv2.imshow('Foreground',fgmask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
