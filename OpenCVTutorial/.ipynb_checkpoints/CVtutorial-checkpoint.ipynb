{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Tutorial\n",
    "Open CV Tutorial for processing video and images \\\n",
    "Code contains some command of openCV and implementation of readymade blocks from some blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "print( cv2.__version__ )\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing video from webcam and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[15  4 10]\n",
      "  [16  5 11]\n",
      "  [16  6 10]\n",
      "  ...\n",
      "  [22  9 13]\n",
      "  [22  9 13]\n",
      "  [22  9 13]]\n",
      "\n",
      " [[18  5 10]\n",
      "  [18  5 10]\n",
      "  [16  6 10]\n",
      "  ...\n",
      "  [22  9 13]\n",
      "  [22  9 13]\n",
      "  [22  9 13]]\n",
      "\n",
      " [[18  5 10]\n",
      "  [17  4  9]\n",
      "  [18  5 10]\n",
      "  ...\n",
      "  [20  9 13]\n",
      "  [22  9 13]\n",
      "  [22  9 13]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[18  5 10]\n",
      "  [18  5 10]\n",
      "  [19  4  9]\n",
      "  ...\n",
      "  [27  7 12]\n",
      "  [25  7 12]\n",
      "  [25  7 12]]\n",
      "\n",
      " [[18  5 10]\n",
      "  [18  5 10]\n",
      "  [19  4  9]\n",
      "  ...\n",
      "  [27  7 12]\n",
      "  [25  7 12]\n",
      "  [25  7 12]]\n",
      "\n",
      " [[20  5 10]\n",
      "  [19  4  9]\n",
      "  [21  3  9]\n",
      "  ...\n",
      "  [27  5 11]\n",
      "  [29  6 12]\n",
      "  [29  6 12]]]\n",
      "ret True\n",
      "[[[27 14 25]\n",
      "  [27 14 25]\n",
      "  [25 14 25]\n",
      "  ...\n",
      "  [34 35 32]\n",
      "  [35 37 32]\n",
      "  [36 38 33]]\n",
      "\n",
      " [[26 16 25]\n",
      "  [26 16 25]\n",
      "  [26 15 26]\n",
      "  ...\n",
      "  [34 35 32]\n",
      "  [34 35 31]\n",
      "  [34 35 31]]\n",
      "\n",
      " [[26 15 28]\n",
      "  [27 16 29]\n",
      "  [27 17 27]\n",
      "  ...\n",
      "  [37 34 37]\n",
      "  [34 35 32]\n",
      "  [31 32 30]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[35 22 22]\n",
      "  [33 19 19]\n",
      "  [43 13 20]\n",
      "  ...\n",
      "  [52 27 29]\n",
      "  [54 27 27]\n",
      "  [53 26 26]]\n",
      "\n",
      " [[37 17 23]\n",
      "  [37 17 23]\n",
      "  [43 13 20]\n",
      "  ...\n",
      "  [50 23 30]\n",
      "  [53 25 28]\n",
      "  [53 25 28]]\n",
      "\n",
      " [[41 16 23]\n",
      "  [39 14 20]\n",
      "  [44 12 19]\n",
      "  ...\n",
      "  [54 19 27]\n",
      "  [58 19 27]\n",
      "  [59 20 28]]]\n",
      "ret True\n",
      "[[[26 13 24]\n",
      "  [26 13 24]\n",
      "  [26 13 22]\n",
      "  ...\n",
      "  [33 28 38]\n",
      "  [32 27 37]\n",
      "  [32 27 37]]\n",
      "\n",
      " [[25 14 25]\n",
      "  [24 13 24]\n",
      "  [24 11 23]\n",
      "  ...\n",
      "  [33 28 38]\n",
      "  [33 28 38]\n",
      "  [32 27 37]]\n",
      "\n",
      " [[27 14 25]\n",
      "  [26 13 24]\n",
      "  [26 13 24]\n",
      "  ...\n",
      "  [32 26 38]\n",
      "  [33 28 38]\n",
      "  [33 28 38]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[34 21 21]\n",
      "  [33 19 19]\n",
      "  [42 20 19]\n",
      "  ...\n",
      "  [59 24 32]\n",
      "  [59 22 31]\n",
      "  [59 22 31]]\n",
      "\n",
      " [[39 18 19]\n",
      "  [39 18 19]\n",
      "  [42 19 21]\n",
      "  ...\n",
      "  [52 22 30]\n",
      "  [57 20 28]\n",
      "  [56 19 27]]\n",
      "\n",
      " [[41 18 19]\n",
      "  [39 16 17]\n",
      "  [41 19 18]\n",
      "  ...\n",
      "  [53 24 31]\n",
      "  [58 17 30]\n",
      "  [58 17 30]]]\n",
      "ret True\n",
      "[[[28 12 24]\n",
      "  [28 12 24]\n",
      "  [26 13 24]\n",
      "  ...\n",
      "  [37 31 34]\n",
      "  [33 30 33]\n",
      "  [33 30 33]]\n",
      "\n",
      " [[26 13 24]\n",
      "  [26 13 24]\n",
      "  [26 13 24]\n",
      "  ...\n",
      "  [35 31 34]\n",
      "  [33 30 33]\n",
      "  [33 30 33]]\n",
      "\n",
      " [[26 13 24]\n",
      "  [26 13 24]\n",
      "  [27 14 25]\n",
      "  ...\n",
      "  [35 31 34]\n",
      "  [35 30 33]\n",
      "  [34 29 32]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[39 14 20]\n",
      "  [39 14 20]\n",
      "  [43 13 20]\n",
      "  ...\n",
      "  [60 28 35]\n",
      "  [61 26 34]\n",
      "  [60 25 33]]\n",
      "\n",
      " [[40 15 21]\n",
      "  [38 13 19]\n",
      "  [45 13 20]\n",
      "  ...\n",
      "  [63 26 34]\n",
      "  [62 26 30]\n",
      "  [59 24 28]]\n",
      "\n",
      " [[41 16 23]\n",
      "  [39 14 20]\n",
      "  [43 13 20]\n",
      "  ...\n",
      "  [63 26 34]\n",
      "  [63 28 31]\n",
      "  [62 26 30]]]\n",
      "ret True\n",
      "[[[ 49  48  59]\n",
      "  [ 49  48  59]\n",
      "  [ 47  48  59]\n",
      "  ...\n",
      "  [ 60  75  71]\n",
      "  [ 60  77  67]\n",
      "  [ 60  77  67]]\n",
      "\n",
      " [[ 49  48  59]\n",
      "  [ 49  48  59]\n",
      "  [ 49  48  59]\n",
      "  ...\n",
      "  [ 58  76  71]\n",
      "  [ 60  77  67]\n",
      "  [ 60  77  67]]\n",
      "\n",
      " [[ 49  47  61]\n",
      "  [ 48  46  60]\n",
      "  [ 49  48  59]\n",
      "  ...\n",
      "  [ 61  76  72]\n",
      "  [ 63  76  72]\n",
      "  [ 62  75  71]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66  52  52]\n",
      "  [ 63  50  50]\n",
      "  [ 67  50  48]\n",
      "  ...\n",
      "  [101  74  81]\n",
      "  [ 98  78  83]\n",
      "  [ 96  76  82]]\n",
      "\n",
      " [[ 66  52  52]\n",
      "  [ 64  51  51]\n",
      "  [ 71  50  49]\n",
      "  ...\n",
      "  [ 97  71  80]\n",
      "  [ 93  73  78]\n",
      "  [ 92  72  77]]\n",
      "\n",
      " [[ 66  52  52]\n",
      "  [ 66  52  52]\n",
      "  [ 66  53  50]\n",
      "  ...\n",
      "  [ 91  70  78]\n",
      "  [ 89  71  76]\n",
      "  [ 91  73  78]]]\n",
      "ret True\n",
      "[[[42 50 60]\n",
      "  [43 51 62]\n",
      "  [43 51 62]\n",
      "  ...\n",
      "  [59 75 75]\n",
      "  [63 75 73]\n",
      "  [63 75 73]]\n",
      "\n",
      " [[42 51 59]\n",
      "  [43 52 60]\n",
      "  [42 51 59]\n",
      "  ...\n",
      "  [60 74 74]\n",
      "  [63 75 73]\n",
      "  [63 75 73]]\n",
      "\n",
      " [[43 50 58]\n",
      "  [44 51 59]\n",
      "  [41 50 58]\n",
      "  ...\n",
      "  [60 75 72]\n",
      "  [62 74 72]\n",
      "  [63 75 73]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[71 51 56]\n",
      "  [71 51 56]\n",
      "  [74 49 55]\n",
      "  ...\n",
      "  [98 71 77]\n",
      "  [97 74 75]\n",
      "  [99 76 78]]\n",
      "\n",
      " [[73 50 56]\n",
      "  [73 50 56]\n",
      "  [75 47 54]\n",
      "  ...\n",
      "  [93 72 73]\n",
      "  [96 73 72]\n",
      "  [97 75 74]]\n",
      "\n",
      " [[69 53 53]\n",
      "  [68 52 52]\n",
      "  [71 50 51]\n",
      "  ...\n",
      "  [94 69 75]\n",
      "  [95 71 73]\n",
      "  [95 71 73]]]\n",
      "ret True\n",
      "[[[ 57  63  73]\n",
      "  [ 58  64  74]\n",
      "  [ 58  61  79]\n",
      "  ...\n",
      "  [ 69  96  89]\n",
      "  [ 76  93  88]\n",
      "  [ 77  94  89]]\n",
      "\n",
      " [[ 59  63  72]\n",
      "  [ 59  63  72]\n",
      "  [ 58  63  76]\n",
      "  ...\n",
      "  [ 77  94  89]\n",
      "  [ 81  94  88]\n",
      "  [ 81  94  88]]\n",
      "\n",
      " [[ 61  62  73]\n",
      "  [ 60  61  72]\n",
      "  [ 61  61  75]\n",
      "  ...\n",
      "  [ 78  92  90]\n",
      "  [ 80  92  88]\n",
      "  [ 81  94  89]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 81  69  64]\n",
      "  [ 81  69  64]\n",
      "  [ 85  64  63]\n",
      "  ...\n",
      "  [111  88  89]\n",
      "  [110  88  85]\n",
      "  [109  87  84]]\n",
      "\n",
      " [[ 83  70  68]\n",
      "  [ 84  71  69]\n",
      "  [ 87  67  65]\n",
      "  ...\n",
      "  [111  85  87]\n",
      "  [113  85  85]\n",
      "  [112  84  84]]\n",
      "\n",
      " [[ 86  65  66]\n",
      "  [ 86  65  66]\n",
      "  [ 85  63  62]\n",
      "  ...\n",
      "  [116  81  89]\n",
      "  [114  81  85]\n",
      "  [114  81  85]]]\n",
      "ret True\n",
      "[[[ 60  56  74]\n",
      "  [ 61  57  76]\n",
      "  [ 56  59  77]\n",
      "  ...\n",
      "  [ 75  94  91]\n",
      "  [ 81  93  91]\n",
      "  [ 81  93  91]]\n",
      "\n",
      " [[ 57  59  72]\n",
      "  [ 58  60  74]\n",
      "  [ 59  61  75]\n",
      "  ...\n",
      "  [ 79  94  89]\n",
      "  [ 81  93  91]\n",
      "  [ 81  93  91]]\n",
      "\n",
      " [[ 58  60  74]\n",
      "  [ 59  61  75]\n",
      "  [ 58  64  74]\n",
      "  ...\n",
      "  [ 79  94  89]\n",
      "  [ 79  93  91]\n",
      "  [ 78  92  90]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78  66  66]\n",
      "  [ 76  65  65]\n",
      "  [ 85  60  67]\n",
      "  ...\n",
      "  [118  83  91]\n",
      "  [116  86  94]\n",
      "  [118  89  96]]\n",
      "\n",
      " [[ 79  68  65]\n",
      "  [ 78  67  64]\n",
      "  [ 87  62  68]\n",
      "  ...\n",
      "  [113  83  90]\n",
      "  [111  85  94]\n",
      "  [114  89  97]]\n",
      "\n",
      " [[ 77  70  64]\n",
      "  [ 76  68  63]\n",
      "  [ 82  66  66]\n",
      "  ...\n",
      "  [109  82  89]\n",
      "  [112  85  91]\n",
      "  [115  88  95]]]\n",
      "ret True\n",
      "[[[ 66  72  82]\n",
      "  [ 69  74  85]\n",
      "  [ 69  75  83]\n",
      "  ...\n",
      "  [ 95 108 102]\n",
      "  [ 96 109  96]\n",
      "  [ 94 108  94]]\n",
      "\n",
      " [[ 64  72  82]\n",
      "  [ 67  75  85]\n",
      "  [ 68  77  84]\n",
      "  ...\n",
      "  [ 95 109 100]\n",
      "  [ 95 112  95]\n",
      "  [ 94 110  94]]\n",
      "\n",
      " [[ 62  73  82]\n",
      "  [ 64  74  84]\n",
      "  [ 68  77  84]\n",
      "  ...\n",
      "  [ 92 106  99]\n",
      "  [100 107  99]\n",
      "  [100 107  99]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[109  77  84]\n",
      "  [107  74  82]\n",
      "  [109  72  81]\n",
      "  ...\n",
      "  [131 104 104]\n",
      "  [134 102 103]\n",
      "  [134 102 103]]\n",
      "\n",
      " [[111  76  84]\n",
      "  [111  76  84]\n",
      "  [112  75  83]\n",
      "  ...\n",
      "  [131 101 102]\n",
      "  [133 100 103]\n",
      "  [132  99 102]]\n",
      "\n",
      " [[110  75  83]\n",
      "  [109  74  82]\n",
      "  [110  75  83]\n",
      "  ...\n",
      "  [131 100 103]\n",
      "  [132  99 102]\n",
      "  [130  97 100]]]\n",
      "ret True\n",
      "[[[ 70  69  87]\n",
      "  [ 70  69  87]\n",
      "  [ 72  70  84]\n",
      "  ...\n",
      "  [ 81 106 100]\n",
      "  [ 81 107  98]\n",
      "  [ 82 108  99]]\n",
      "\n",
      " [[ 70  72  85]\n",
      "  [ 71  73  86]\n",
      "  [ 73  74  85]\n",
      "  ...\n",
      "  [ 86 106 101]\n",
      "  [ 88 107  99]\n",
      "  [ 87 106  98]]\n",
      "\n",
      " [[ 70  70  84]\n",
      "  [ 73  73  86]\n",
      "  [ 73  74  85]\n",
      "  ...\n",
      "  [ 87 108 102]\n",
      "  [ 90 106  99]\n",
      "  [ 89 105  98]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[104  76  85]\n",
      "  [103  74  84]\n",
      "  [106  72  80]\n",
      "  ...\n",
      "  [134  99 100]\n",
      "  [144  92 103]\n",
      "  [144  92 103]]\n",
      "\n",
      " [[102  78  80]\n",
      "  [102  78  80]\n",
      "  [105  75  82]\n",
      "  ...\n",
      "  [135  97 101]\n",
      "  [143  94 104]\n",
      "  [143  94 104]]\n",
      "\n",
      " [[105  78  84]\n",
      "  [105  78  84]\n",
      "  [105  78  84]\n",
      "  ...\n",
      "  [135  95 104]\n",
      "  [141  94 104]\n",
      "  [141  94 104]]]\n",
      "ret True\n",
      "[[[ 48  79 103]\n",
      "  [ 51  81 106]\n",
      "  [ 46  86 102]\n",
      "  ...\n",
      "  [ 71 121 109]\n",
      "  [ 67 124 105]\n",
      "  [ 67 124 105]]\n",
      "\n",
      " [[ 49  77 102]\n",
      "  [ 53  81 106]\n",
      "  [ 48  85 102]\n",
      "  ...\n",
      "  [ 75 120 109]\n",
      "  [ 69 123 105]\n",
      "  [ 69 123 105]]\n",
      "\n",
      " [[ 52  80 103]\n",
      "  [ 53  81 104]\n",
      "  [ 53  88  98]\n",
      "  ...\n",
      "  [ 72 119 109]\n",
      "  [ 71 122 107]\n",
      "  [ 71 122 107]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86  89  88]\n",
      "  [ 88  90  90]\n",
      "  [ 89  94  86]\n",
      "  ...\n",
      "  [124 113 112]\n",
      "  [124 111 116]\n",
      "  [124 111 116]]\n",
      "\n",
      " [[ 91  94  84]\n",
      "  [ 86  89  80]\n",
      "  [ 86  89  81]\n",
      "  ...\n",
      "  [121 112 111]\n",
      "  [119 113 111]\n",
      "  [118 111 110]]\n",
      "\n",
      " [[ 92  95  86]\n",
      "  [ 88  92  82]\n",
      "  [ 87  88  79]\n",
      "  ...\n",
      "  [121 111 115]\n",
      "  [118 111 110]\n",
      "  [117 110 109]]]\n",
      "ret True\n",
      "[[[ 50  81 103]\n",
      "  [ 48  80 102]\n",
      "  [ 50  79 102]\n",
      "  ...\n",
      "  [ 76 118 109]\n",
      "  [ 77 117 106]\n",
      "  [ 76 116 105]]\n",
      "\n",
      " [[ 50  81 103]\n",
      "  [ 48  80 102]\n",
      "  [ 50  80 100]\n",
      "  ...\n",
      "  [ 77 120 109]\n",
      "  [ 76 119 107]\n",
      "  [ 76 119 107]]\n",
      "\n",
      " [[ 52  81 101]\n",
      "  [ 53  82 103]\n",
      "  [ 53  83 101]\n",
      "  ...\n",
      "  [ 73 120 110]\n",
      "  [ 77 120 109]\n",
      "  [ 77 120 109]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87  99  91]\n",
      "  [ 85  97  88]\n",
      "  [ 90  91  86]\n",
      "  ...\n",
      "  [127 114 114]\n",
      "  [127 114 114]\n",
      "  [127 114 114]]\n",
      "\n",
      " [[ 88  96  93]\n",
      "  [ 85  93  89]\n",
      "  [ 88  91  88]\n",
      "  ...\n",
      "  [129 112 117]\n",
      "  [129 112 117]\n",
      "  [129 112 117]]\n",
      "\n",
      " [[ 89  95  92]\n",
      "  [ 87  92  89]\n",
      "  [ 88  91  88]\n",
      "  ...\n",
      "  [129 112 117]\n",
      "  [128 111 116]\n",
      "  [128 111 116]]]\n",
      "ret True\n",
      "[[[ 59  98 112]\n",
      "  [ 61  99 113]\n",
      "  [ 65 101 109]\n",
      "  ...\n",
      "  [ 84 130 122]\n",
      "  [ 84 130 122]\n",
      "  [ 84 130 122]]\n",
      "\n",
      " [[ 64  96 111]\n",
      "  [ 64  96 111]\n",
      "  [ 66  98 106]\n",
      "  ...\n",
      "  [ 84 130 122]\n",
      "  [ 85 131 123]\n",
      "  [ 85 131 123]]\n",
      "\n",
      " [[ 66  96 109]\n",
      "  [ 66  96 109]\n",
      "  [ 68  98 105]\n",
      "  ...\n",
      "  [ 85 132 122]\n",
      "  [ 86 129 122]\n",
      "  [ 87 130 123]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 95 104  98]\n",
      "  [ 94 103  97]\n",
      "  [100 102  97]\n",
      "  ...\n",
      "  [141 127 122]\n",
      "  [139 126 124]\n",
      "  [139 126 124]]\n",
      "\n",
      " [[ 94 103  97]\n",
      "  [ 94 103  97]\n",
      "  [100 102  97]\n",
      "  ...\n",
      "  [141 127 120]\n",
      "  [138 125 123]\n",
      "  [138 125 123]]\n",
      "\n",
      " [[ 98 102  97]\n",
      "  [ 98 102  97]\n",
      "  [100 102  97]\n",
      "  ...\n",
      "  [140 125 121]\n",
      "  [138 126 121]\n",
      "  [137 125 120]]]\n",
      "ret True\n",
      "[[[ 57  96 110]\n",
      "  [ 57  96 110]\n",
      "  [ 61  96 108]\n",
      "  ...\n",
      "  [ 93 129 116]\n",
      "  [ 96 128 121]\n",
      "  [ 95 127 119]]\n",
      "\n",
      " [[ 53  96 110]\n",
      "  [ 53  96 110]\n",
      "  [ 57  96 108]\n",
      "  ...\n",
      "  [ 91 129 118]\n",
      "  [ 91 129 118]\n",
      "  [ 91 129 118]]\n",
      "\n",
      " [[ 57  96 110]\n",
      "  [ 57  96 110]\n",
      "  [ 63  96 107]\n",
      "  ...\n",
      "  [ 90 130 119]\n",
      "  [ 91 128 119]\n",
      "  [ 91 128 119]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 98 103  95]\n",
      "  [ 98 103  95]\n",
      "  [ 98  99  95]\n",
      "  ...\n",
      "  [140 128 123]\n",
      "  [143 126 122]\n",
      "  [142 125 121]]\n",
      "\n",
      " [[100 101  99]\n",
      "  [ 99 100  97]\n",
      "  [ 99 100  97]\n",
      "  ...\n",
      "  [142 128 123]\n",
      "  [138 125 123]\n",
      "  [138 125 123]]\n",
      "\n",
      " [[102  99 102]\n",
      "  [102  99 102]\n",
      "  [100 101  99]\n",
      "  ...\n",
      "  [141 126 124]\n",
      "  [138 125 123]\n",
      "  [137 124 121]]]\n",
      "ret True\n",
      "[[[ 75  99 109]\n",
      "  [ 76 100 110]\n",
      "  [ 74 102 106]\n",
      "  ...\n",
      "  [ 91 135 121]\n",
      "  [ 91 136 119]\n",
      "  [ 93 137 120]]\n",
      "\n",
      " [[ 77  98 109]\n",
      "  [ 78 100 110]\n",
      "  [ 74 102 106]\n",
      "  ...\n",
      "  [ 93 135 124]\n",
      "  [ 89 138 120]\n",
      "  [ 89 138 120]]\n",
      "\n",
      " [[ 74  98 106]\n",
      "  [ 76 101 108]\n",
      "  [ 72 103 105]\n",
      "  ...\n",
      "  [ 89 135 125]\n",
      "  [ 90 136 126]\n",
      "  [ 89 135 125]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[102 105 102]\n",
      "  [103 106 103]\n",
      "  [104 105 100]\n",
      "  ...\n",
      "  [151 126 132]\n",
      "  [151 124 131]\n",
      "  [153 125 132]]\n",
      "\n",
      " [[ 98 105 104]\n",
      "  [ 99 106 105]\n",
      "  [100 103 102]\n",
      "  ...\n",
      "  [149 124 131]\n",
      "  [149 124 131]\n",
      "  [149 124 131]]\n",
      "\n",
      " [[100 103 102]\n",
      "  [100 103 102]\n",
      "  [104 101 104]\n",
      "  ...\n",
      "  [147 128 129]\n",
      "  [147 126 128]\n",
      "  [147 126 128]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret True\n",
      "[[[ 71  97 113]\n",
      "  [ 71  97 113]\n",
      "  [ 73  98 110]\n",
      "  ...\n",
      "  [ 94 135 126]\n",
      "  [ 97 138 124]\n",
      "  [ 97 138 124]]\n",
      "\n",
      " [[ 65  96 114]\n",
      "  [ 68  98 116]\n",
      "  [ 70 100 111]\n",
      "  ...\n",
      "  [ 91 137 128]\n",
      "  [ 96 139 127]\n",
      "  [ 96 139 127]]\n",
      "\n",
      " [[ 62  99 116]\n",
      "  [ 62  99 116]\n",
      "  [ 69 103 111]\n",
      "  ...\n",
      "  [ 95 136 129]\n",
      "  [ 95 136 129]\n",
      "  [ 95 136 129]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[106 105 100]\n",
      "  [107 106 102]\n",
      "  [110 104 100]\n",
      "  ...\n",
      "  [149 131 130]\n",
      "  [150 130 127]\n",
      "  [150 130 127]]\n",
      "\n",
      " [[105 106 102]\n",
      "  [105 106 102]\n",
      "  [108 102 101]\n",
      "  ...\n",
      "  [148 132 125]\n",
      "  [149 130 124]\n",
      "  [149 130 124]]\n",
      "\n",
      " [[108 104 102]\n",
      "  [108 104 102]\n",
      "  [112 101 105]\n",
      "  ...\n",
      "  [144 130 126]\n",
      "  [147 130 124]\n",
      "  [145 129 123]]]\n",
      "ret True\n",
      "[[[ 77  96 113]\n",
      "  [ 79  98 116]\n",
      "  [ 76 103 110]\n",
      "  ...\n",
      "  [102 133 128]\n",
      "  [102 133 128]\n",
      "  [103 134 129]]\n",
      "\n",
      " [[ 74 100 110]\n",
      "  [ 75 101 111]\n",
      "  [ 74 103 112]\n",
      "  ...\n",
      "  [101 135 129]\n",
      "  [101 135 128]\n",
      "  [102 137 129]]\n",
      "\n",
      " [[ 73  99 109]\n",
      "  [ 75 101 111]\n",
      "  [ 73 105 113]\n",
      "  ...\n",
      "  [103 135 128]\n",
      "  [103 135 128]\n",
      "  [104 136 129]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[102 110 107]\n",
      "  [101 109 105]\n",
      "  [104 107 104]\n",
      "  ...\n",
      "  [146 130 128]\n",
      "  [151 129 126]\n",
      "  [149 128 124]]\n",
      "\n",
      " [[101 108 107]\n",
      "  [101 108 107]\n",
      "  [104 107 104]\n",
      "  ...\n",
      "  [150 129 130]\n",
      "  [151 129 126]\n",
      "  [151 129 126]]\n",
      "\n",
      " [[105 107 109]\n",
      "  [105 107 109]\n",
      "  [107 108 105]\n",
      "  ...\n",
      "  [151 127 129]\n",
      "  [151 129 126]\n",
      "  [151 129 126]]]\n",
      "ret True\n",
      "[[[ 77 101 111]\n",
      "  [ 76 100 110]\n",
      "  [ 78 100 108]\n",
      "  ...\n",
      "  [ 92 138 130]\n",
      "  [ 89 136 131]\n",
      "  [ 89 136 131]]\n",
      "\n",
      " [[ 75 102 109]\n",
      "  [ 74 101 108]\n",
      "  [ 78 100 108]\n",
      "  ...\n",
      "  [ 92 138 130]\n",
      "  [ 92 137 132]\n",
      "  [ 92 137 132]]\n",
      "\n",
      " [[ 78 100 110]\n",
      "  [ 79 101 111]\n",
      "  [ 78 100 108]\n",
      "  ...\n",
      "  [ 96 137 130]\n",
      "  [ 96 136 132]\n",
      "  [ 96 136 132]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[115 106 105]\n",
      "  [114 105 104]\n",
      "  [118 100 105]\n",
      "  ...\n",
      "  [153 125 128]\n",
      "  [156 122 130]\n",
      "  [159 124 132]]\n",
      "\n",
      " [[115 107 104]\n",
      "  [113 105 102]\n",
      "  [117  99 104]\n",
      "  ...\n",
      "  [151 126 128]\n",
      "  [155 123 131]\n",
      "  [155 123 131]]\n",
      "\n",
      " [[116 106 103]\n",
      "  [114 103 100]\n",
      "  [119 100 101]\n",
      "  ...\n",
      "  [151 126 128]\n",
      "  [157 126 129]\n",
      "  [155 125 128]]]\n",
      "ret True\n",
      "[[[ 73 101 120]\n",
      "  [ 73 101 120]\n",
      "  [ 72 103 121]\n",
      "  ...\n",
      "  [115 137 131]\n",
      "  [114 139 132]\n",
      "  [114 139 132]]\n",
      "\n",
      " [[ 73 101 120]\n",
      "  [ 73 101 120]\n",
      "  [ 73 101 120]\n",
      "  ...\n",
      "  [115 137 131]\n",
      "  [114 139 132]\n",
      "  [113 137 131]]\n",
      "\n",
      " [[ 78  98 120]\n",
      "  [ 78  98 120]\n",
      "  [ 79 102 121]\n",
      "  ...\n",
      "  [113 137 131]\n",
      "  [110 137 133]\n",
      "  [112 138 134]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119 114 108]\n",
      "  [118 113 107]\n",
      "  [121 112 104]\n",
      "  ...\n",
      "  [156 137 131]\n",
      "  [160 139 133]\n",
      "  [160 139 133]]\n",
      "\n",
      " [[116 114 105]\n",
      "  [116 114 105]\n",
      "  [121 110 107]\n",
      "  ...\n",
      "  [152 136 130]\n",
      "  [157 138 132]\n",
      "  [158 139 133]]\n",
      "\n",
      " [[118 112 109]\n",
      "  [118 112 109]\n",
      "  [120 112 109]\n",
      "  ...\n",
      "  [147 134 132]\n",
      "  [151 140 131]\n",
      "  [151 140 131]]]\n",
      "ret True\n",
      "[[[ 66 106 122]\n",
      "  [ 67 107 123]\n",
      "  [ 69 110 117]\n",
      "  ...\n",
      "  [109 137 130]\n",
      "  [109 139 125]\n",
      "  [110 140 126]]\n",
      "\n",
      " [[ 69 101 121]\n",
      "  [ 70 102 122]\n",
      "  [ 70 106 116]\n",
      "  ...\n",
      "  [106 139 131]\n",
      "  [110 139 130]\n",
      "  [110 139 130]]\n",
      "\n",
      " [[ 69  99 119]\n",
      "  [ 70 100 120]\n",
      "  [ 72 105 118]\n",
      "  ...\n",
      "  [102 139 131]\n",
      "  [104 140 130]\n",
      "  [104 140 130]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[110 116 104]\n",
      "  [109 115 103]\n",
      "  [114 109 105]\n",
      "  ...\n",
      "  [162 141 136]\n",
      "  [158 145 138]\n",
      "  [158 145 138]]\n",
      "\n",
      " [[111 113 106]\n",
      "  [109 112 105]\n",
      "  [114 109 105]\n",
      "  ...\n",
      "  [159 140 136]\n",
      "  [154 141 139]\n",
      "  [154 141 139]]\n",
      "\n",
      " [[115 111 107]\n",
      "  [112 109 105]\n",
      "  [115 110 106]\n",
      "  ...\n",
      "  [158 138 136]\n",
      "  [153 140 138]\n",
      "  [153 140 138]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0\n",
    "frames = 20\n",
    "while(count < frames):\n",
    "    count += 1\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    print('ret',ret)\n",
    "    print(frame)\n",
    "    # Our operations on the frame come here    \n",
    "    img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(frame,1)   # flip left-right  \n",
    "    # img = cv2.flip(img,0)     # flip up-down\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record and Save the Video from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create writer object\n",
    "fileName='out.avi'  # change the file name if needed\n",
    "imgSize=(640,480)\n",
    "frame_per_second=30.0\n",
    "writer = cv2.VideoWriter(fileName, cv2.VideoWriter_fourcc(*\"MJPG\"), frame_per_second,imgSize)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "start_time = time.time()\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        writer.write(frame)                   # save the frame into video file\n",
    "        cv2.imshow('Video Capture',frame)     # show on the screen\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # press q to Quit, where? : In video window\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the video and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='out.avi'  # change the file name if needed\n",
    "\n",
    "cap = cv2.VideoCapture(fileName)          # load the video\n",
    "while(cap.isOpened()):                    # play the video by reading frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        # optional: do some image processing here \n",
    "        cv2.imshow('frame',frame)              # show the video\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the recording window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factorx=0.5\n",
    "scaling_factory=0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # set frame size (e.g. 640x480; 320x240; 960x720), larger is slower    \n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_WIDTH,320)\n",
    "    #ret = cap.set(cv2.CAP_PROP_FRAME_HEIGHT,240)\n",
    "    frame=cv2.resize(frame,None,fx=scaling_factorx,fy=scaling_factory,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    img = frame\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Smaller Window',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-njn2fp78/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-918111990c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HLS)   # RGB color to HLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HLS)   # BGR color to HLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2XYZ\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# RGB color to CIE XYZ.Rec 709\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2XYZ)   # RGB color to CIE XYZ.Rec 709\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2Lab)   # BGR color to CIE L\\*a\\*b\\*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-njn2fp78/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "### Colour Transformation\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR color to RGB\n",
    "#     img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # RGB color to BGR\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)  # BGR color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)  # RGB color to gray level\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)   # BGR color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HSV)   # RGB color to HSV\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2HLS)   # RGB color to HLS\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2HLS)   # BGR color to HLS\n",
    "    img = cv2.cvtColor(frame,cv2.COLOR_BGR2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2XYZ)   # RGB color to CIE XYZ.Rec 709\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_BGR2Lab)   # BGR color to CIE L\\*a\\*b\\*\n",
    "#     img = cv2.cvtColor(frame,cv2.COLOR_RGB2Luv)   # RGB color to CIE L\\*u\\*v\\*\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Gray',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Enhancement\n",
    "\n",
    "Change the contrast of image using Histogram equalization. \\\n",
    "command : equalizeHist() -- only for gray scale image \\\n",
    "\n",
    "Ref : https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()        \n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    #img = frame\n",
    "    img = equalizeHistColor(frame)\n",
    "    \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Histogram Equalization',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def WarpImage(frame):\n",
    "    ax,bx=10.0,100\n",
    "    ay,by=20.0,120\n",
    "    img=np.zeros(frame.shape,dtype=frame.dtype)\n",
    "    rows,cols=img.shape[:2]\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            offset_x=int(ax*math.sin(2*math.pi*i/bx))\n",
    "            offset_y=int(ay*math.cos(2*math.pi*j/by))\n",
    "            if i+offset_y<rows and j+offset_x<cols:\n",
    "                img[i,j]=frame[(i+offset_y)%rows,(j+offset_x)%cols]\n",
    "            else:\n",
    "                img[i,j]=0\n",
    "    return img\n",
    "\n",
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "# start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read() \n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    if ret==1:\n",
    "        #img = WarpImage(frame)\n",
    "        img = equalizeHistColor(WarpImage(frame))\n",
    "    else:\n",
    "        img = equalizeHistColor(frame)\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Warped',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=5\n",
    "parameter2=20\n",
    "intApertureSize=10\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    ## Smoothening Filters   \n",
    "    frame = cv2.GaussianBlur(frame, (kernelSize,kernelSize),0,0) # Gaussian Blur smoothing filter\n",
    "#     frame = cv2.medianBlur(frame, kernelSize) # Median Blur smoothing filter\n",
    "#     frame = cv2.blur(frame,(kernelSize,kernelSize)) # Average Blur smoothing filter\n",
    "#     frame = cv2.bilateralFilter(frame,9,75,75) # Bilateral Filter for smoothing filter\n",
    "    \n",
    "    ## Edge Detection Algorithm\n",
    "    frame = cv2.Canny(frame,parameter1,parameter2,intApertureSize) # Canny edge detection\n",
    "    frame = cv2.Laplacian(frame,cv2.CV_64F) # Laplacian edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,1,0,ksize=kernelSize) # X-direction Sobel edge detection\n",
    "    frame = cv2.Sobel(frame,cv2.CV_64F,0,1,ksize=kernelSize) # Y-direction Sobel edge detection\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Canny',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Impose\n",
    "\n",
    "- edge detection as mask\n",
    "- superimpose it with the original image\n",
    "- Processing : reverse the edge detection result using bitwise Not to inverse it. Then, use bitwise and to superimpose with the blur image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernelSize=21   # Kernel Bluring size \n",
    "\n",
    "# Edge Detection Parameter\n",
    "parameter1=10\n",
    "parameter2=40\n",
    "intApertureSize=1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame1 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    frame = cv2.GaussianBlur(frame1, (kernelSize,kernelSize), 0, 0) \n",
    "    edge = cv2.Canny(frame,parameter1,parameter2,intApertureSize)  # Canny edge detection\n",
    "    mask_edge = cv2.bitwise_not(edge)\n",
    "    frame = cv2.bitwise_and(frame1,frame1,mask = mask_edge)   \n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Super Impose',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countour\n",
    "\n",
    "Functions:\n",
    "    - img, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,chainRuleApproximation)\n",
    "    - img=cv2.drawContours(img, contours, index, colorTuple, thickness)\n",
    "\n",
    "Arguments:\n",
    "    - img = image\n",
    "    - index=-1 means show all contours, 0-len(contours) means to show each contour\n",
    "    - chainRuleApproximation is either:\n",
    "        - cv2.CHAIN_APPROX_SIMPLE: to give only 4 points in a rectangle\n",
    "        - cv2.CHAIN_APPROX_NONE: to give all points\n",
    "    - colorTuple is any BGR color. For instance:\n",
    "        - (255,0,0) for Blue\n",
    "        - (0,255,0) for Green\n",
    "        - (0,0,255) for Red\n",
    "    - thickness is integer 1-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(gray,10,20,cv2.THRESH_BINARY_INV)\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)   \n",
    "    if len(contours) != 0:\n",
    "            c = max(contours, key = cv2.contourArea) # find the largest contour\n",
    "            x,y,w,h = cv2.boundingRect(c)          # get bounding box of largest contour\n",
    "            #img2=cv2.drawContours(frame, c, -1, color, thickness) # draw largest contour\n",
    "            img2=cv2.drawContours(frame, contours, -1, color, thickness) # draw all contours\n",
    "            img3 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Contour',img3)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding\n",
    "\n",
    "-Generate mask using thresold. A mask is a binary image.\n",
    "\n",
    "Adaptive threshold has the following parameters:\n",
    "\n",
    "   - src – Source 8-bit single-channel image.\n",
    "   - dst – Destination image of the same size and the same type as src .\n",
    "   - maxValue – Non-zero value assigned to the pixels for which the condition is satisfied. Put 255.\n",
    "   - adaptiveMethod – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C .\n",
    "   - thresholdType – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV .\n",
    "   - blockSize – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "   - C – Constant subtracted from the mean or weighted mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalizeHistColor(frame):\n",
    "    # equalize the histogram of color image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)  # convert to HSV\n",
    "    img[:,:,2] = cv2.equalizeHist(img[:,:,2])     # equalize the histogram of the V channel\n",
    "    return cv2.cvtColor(img, cv2.COLOR_HSV2RGB)   # convert the HSV image back to RGB format\n",
    "\n",
    "\n",
    "threshold1=100\n",
    "threshold2=200\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # equalize the histogram of color image\n",
    "    frame1 = equalizeHistColor(frame) \n",
    "    gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "     \n",
    "    ## Thresolding Method\n",
    "    ret, mask = cv2.threshold(blur, threshold1, threshold2, cv2.THRESH_BINARY)\n",
    "    ret, mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #ret, mask = cv2.threshold(blur,threshold1, threshold2,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    #mask = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((3, 3), np.uint8)  \n",
    "    mask=cv2.erode(mask,kernel,iterations=7) # morphology erosion   \n",
    "    mask=cv2.dilate(mask,kernel,iterations=5) # morphology dilation\n",
    "    \n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    img = cv2.bitwise_and(frame1,frame1,mask = mask_inv)\n",
    "    img = cv2.addWeighted(frame1,0.1,img,0.9,0)\n",
    "    \n",
    "    #img=mask\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Thresholding-Otsu',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow\n",
    "- shows aura kinda.\n",
    "- motion of image objects between two consecutive frames caused by the movemement of object or camera.\n",
    "Ref : https://docs.opencv.org/3.3.0/d7/d8b/tutorial_py_lucas_kanade.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()    \n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    prvs = next\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Optical Flow Aura',bgr)\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Detection by Image Difference\n",
    "\n",
    "- images are captured with a time delay of 1/25 seconds\n",
    "- After image difference, get the contour out of it \n",
    "- put the bounding box out of the contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(255,0,0)\n",
    "thickness=2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture two frames\n",
    "    ret, frame1 = cap.read()  # first image\n",
    "    time.sleep(1/25)          # slight delay\n",
    "    ret, frame2 = cap.read()  # second image \n",
    "    img1 = cv2.absdiff(frame1,frame2)  # image difference\n",
    "    \n",
    "    # get theshold image\n",
    "    gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(21,21),0)\n",
    "    ret,thresh = cv2.threshold(blur,200,255,cv2.THRESH_OTSU)\n",
    "    \n",
    "    # combine frame and the image difference\n",
    "    img2 = cv2.addWeighted(frame1,0.9,img1,0.1,0)\n",
    "    \n",
    "    # get contours and set bounding box from contours\n",
    "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    if len(contours) != 0:\n",
    "        for c in contours:\n",
    "            rect = cv2.boundingRect(c)\n",
    "            height, width = img3.shape[:2]            \n",
    "            if rect[2] > 0.2*height and rect[2] < 0.7*height and rect[3] > 0.2*width and rect[3] < 0.7*width: \n",
    "                x,y,w,h = cv2.boundingRect(c)            # get bounding box of largest contour\n",
    "                img4=cv2.drawContours(img2, c, -1, color, thickness)\n",
    "                img5 = cv2.rectangle(img2,(x,y),(x+w,y+h),(0,0,255),2)  # draw red bounding box in img\n",
    "            else:\n",
    "                img5=img2\n",
    "    else:\n",
    "        img5=img2\n",
    "        \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Motion Detection by Image Difference',img2)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "folder = './'\n",
    "face_casc = cv2.CascadeClassifier(folder+'haarcascade_frontalface_default.xml')\n",
    "eye_casc=cv2.CascadeClassifier(folder+'haarcascade_eye.xml')\n",
    "\n",
    "color=(0,255,0)\n",
    "thickness=3\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    \n",
    "    # Our operations on the frame come here \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    faces = face_casc.detectMultiScale(gray, scaleFactor=1.1,minNeighbors=3)\n",
    "    \n",
    "    img=frame                     # default if face is not found\n",
    "    for(x,y,w,h) in faces:\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        #img=cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness) # box for face\n",
    "        eyes=eye_casc.detectMultiScale(roi_gray)\n",
    "        for(x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center=(int(x_eye+0.5*w_eye),int(y_eye+0.5*h_eye))\n",
    "            radius=int(0.3*(w_eye+h_eye))\n",
    "            img=cv2.circle(roi_color,center,radius,color,thickness)\n",
    "            #img=cv2.circle(frame,center,radius,color,thickness)\n",
    "\n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Face Detection Harr',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=1\n",
    "isFirstTime=True\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()  # ret = 1 if the video is captured; frame is the image\n",
    "    frame=cv2.resize(frame,None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # create background    \n",
    "    if isFirstTime==True:\n",
    "       bg_img=frame\n",
    "       isFirstTime=False\n",
    "    else:\n",
    "       bg_img = dst = cv2.addWeighted(frame,(1-alpha),bg_img,alpha,0)\n",
    "    # the above code is the same as:\n",
    "    fgmask = bg_img+frame\n",
    "    \n",
    "    # create foreground\n",
    "    fg_img=cv2.subtract(frame,bg_img)\n",
    "#     fg_img = cv2.absdiff(frame,bg_img)  \n",
    "    \n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video Capture',frame)\n",
    "    cv2.imshow('Background',bg_img)\n",
    "    cv2.imshow('Foreground',fgmask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # press q to quit\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
